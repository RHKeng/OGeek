{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "from collections import Counter\n",
    "import functools\n",
    "from gensim.models import word2vec\n",
    "import Levenshtein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prefix                                   query_prediction            title  \\\n",
      "0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...               小品   \n",
      "1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...  HCG大于1368%2C正常吗   \n",
      "2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...            1368年   \n",
      "3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...         银耳红枣汤的做法   \n",
      "4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...         月经量少怎么调理   \n",
      "\n",
      "  tag  label  \n",
      "0  阅读      0  \n",
      "1  健康      0  \n",
      "2  百科      1  \n",
      "3  菜谱      1  \n",
      "4  百科      0  \n",
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \n",
      "0               小品  阅读      0  \n",
      "1  HCG大于1368%2C正常吗  健康      0  \n",
      "2            1368年  百科      1  \n",
      "3         银耳红枣汤的做法  菜谱      1  \n",
      "4         月经量少怎么调理  百科      0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 4 columns):\n",
      "prefix              50000 non-null object\n",
      "query_prediction    50000 non-null object\n",
      "title               50000 non-null object\n",
      "tag                 50000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_table('../data/oppo_round1_train_20180929.txt', names=['prefix', 'query_prediction', 'title', 'tag', 'label'], header=None, quoting=3)\n",
    "valid_df = pd.read_table('../data/oppo_round1_vali_20180929.txt', names=['prefix', 'query_prediction', 'title', 'tag', 'label'], header=None, quoting=3)\n",
    "train_df = pd.concat([train_df, valid_df])\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df['index'] = train_df.index\n",
    "test_df = pd.read_table('../data/oppo_round1_test_A_20180929.txt', names=['prefix', 'query_prediction', 'title', 'tag'], header=None, quoting=3)\n",
    "print(test_df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "   query_prediction_max  query_prediction_min  query_prediction_mean  \\\n",
      "0                 0.198                 0.007               0.037300   \n",
      "1                 0.124                 0.022               0.057778   \n",
      "2                 0.124                 0.022               0.057778   \n",
      "3                 0.114                 0.009               0.040400   \n",
      "4                 0.569                 0.009               0.074700   \n",
      "\n",
      "   query_prediction_std  \n",
      "0              0.056023  \n",
      "1              0.031538  \n",
      "2              0.031538  \n",
      "3              0.030660  \n",
      "4              0.165089  \n"
     ]
    }
   ],
   "source": [
    "def get_float_list(x):\n",
    "    return_list = []\n",
    "    for temp in x:\n",
    "        return_list.append(float(temp))\n",
    "    return return_list\n",
    "\n",
    "# 处理跟query_prediction相关的统计特征\n",
    "def get_query_prediction_feature(df):\n",
    "    df['query_prediction_dict'] = df['query_prediction'].map(lambda x : eval(x))\n",
    "    df['query_prediction_keys'] = df['query_prediction_dict'].map(lambda x : list(x.keys()))\n",
    "    df['query_prediction_values'] = df['query_prediction_dict'].map(lambda x : get_float_list(list(x.values())))\n",
    "    df['query_prediction_number'] = df['query_prediction_keys'].map(lambda x : len(x))\n",
    "    df['query_prediction_max'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.max(x))\n",
    "    df['query_prediction_min'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.min(x))\n",
    "    df['query_prediction_mean'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.mean(x))\n",
    "    df['query_prediction_std'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.std(x))\n",
    "    return df\n",
    "\n",
    "train_df = get_query_prediction_feature(train_df)\n",
    "test_df = get_query_prediction_feature(test_df)\n",
    "print(train_df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix : finish!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : finish!!!\n",
      "tag : finish!!!\n",
      "query_prediction : finish!!!\n",
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "0      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "0      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "0      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "1      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "0  HCG大于1368%2C正常吗  健康      0   \n",
      "0            1368年  百科      1   \n",
      "0         银耳红枣汤的做法  菜谱      1   \n",
      "1         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "0  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "0  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "0  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "1  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "0  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "0  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "0  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "1  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "0  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "0  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "0  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "1  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "               ...                prefix_click_number  title_count  \\\n",
      "0              ...                               40.0         63.0   \n",
      "0              ...                                1.0          NaN   \n",
      "0              ...                                0.0          NaN   \n",
      "0              ...                              176.0        164.0   \n",
      "1              ...                               58.0         66.0   \n",
      "\n",
      "   title_rate  title_click_number  tag_count  tag_rate  tag_click_number  \\\n",
      "0    0.333505                21.0      64029  0.263121             16847   \n",
      "0         NaN                 NaN     114705  0.297547             34130   \n",
      "0         NaN                 NaN     592357  0.395718            234407   \n",
      "0    0.651990               107.0      78160  0.415792             32499   \n",
      "1    0.499502                33.0     592235  0.396386            234754   \n",
      "\n",
      "   query_prediction_count  query_prediction_rate  \\\n",
      "0                   107.0               0.374080   \n",
      "0                     1.0               0.679011   \n",
      "0                     1.0               0.210895   \n",
      "0                   457.0               0.385149   \n",
      "1                   156.0               0.371980   \n",
      "\n",
      "   query_prediction_click_number  \n",
      "0                           40.0  \n",
      "0                            1.0  \n",
      "0                            0.0  \n",
      "0                          176.0  \n",
      "1                           58.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def getBayesSmoothParam(origion_rate):\n",
    "    origion_rate_mean = origion_rate.mean()\n",
    "    origion_rate_var = origion_rate.var()\n",
    "    alpha = origion_rate_mean / origion_rate_var * (origion_rate_mean * (1 - origion_rate_mean) - origion_rate_var)\n",
    "    beta = (1 - origion_rate_mean) / origion_rate_var * (origion_rate_mean * (1 - origion_rate_mean) - origion_rate_var)\n",
    "#     print('origion_rate_mean : ', origion_rate_mean)\n",
    "#     print('origion_rate_var : ', origion_rate_var)\n",
    "#     print('alpha : ', alpha)\n",
    "#     print('beta : ', beta)\n",
    "    return alpha, beta\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2018, shuffle=True)\n",
    "\n",
    "# 统计单维度的转化率特征\n",
    "def get_single_dimension_rate_feature(train_df, valid_df, fea_set):\n",
    "    for fea in fea_set:\n",
    "        train_temp_df = pd.DataFrame()\n",
    "        for index, (train_index, test_index) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "            temp_df = train_df[[fea, 'label']].iloc[train_index].copy()\n",
    "            temp_pivot_table = pd.pivot_table(temp_df, index=fea, values='label', aggfunc={len, np.mean, np.sum})\n",
    "            temp_pivot_table.reset_index(inplace=True)\n",
    "            temp_pivot_table.rename(columns={'len':fea + '_count', 'mean':fea + '_rate', 'sum':fea + '_click_number'}, inplace=True)\n",
    "            alpha, beta = getBayesSmoothParam(temp_pivot_table[fea + '_rate'])\n",
    "            temp_pivot_table[fea + '_rate'] = (temp_pivot_table[fea + '_click_number'] + alpha) / (temp_pivot_table[fea + '_count'] + alpha + beta)\n",
    "#             del temp_pivot_table[fea + '_click_number']\n",
    "            fea_df = train_df.iloc[test_index].copy()\n",
    "            fea_df = pd.merge(fea_df, temp_pivot_table, on=fea, how='left')\n",
    "#             print(fea_df.head())\n",
    "            train_temp_df = pd.concat([train_temp_df, fea_df])\n",
    "        temp_df = train_df[[fea, 'label']].copy()\n",
    "        temp_pivot_table = pd.pivot_table(temp_df, index=fea, values='label', aggfunc={len, np.mean, np.sum})\n",
    "        temp_pivot_table.reset_index(inplace=True)\n",
    "        temp_pivot_table.rename(columns={'len':fea + '_count', 'mean':fea + '_rate', 'sum':fea + '_click_number'}, inplace=True)\n",
    "        alpha, beta = getBayesSmoothParam(temp_pivot_table[fea + '_rate'])\n",
    "        temp_pivot_table[fea + '_rate'] = (temp_pivot_table[fea + '_click_number'] + alpha) / (temp_pivot_table[fea + '_count'] + alpha + beta)\n",
    "#             del temp_pivot_table[fea + '_click_number']\n",
    "        valid_df = pd.merge(valid_df, temp_pivot_table, on=fea, how='left')\n",
    "        print(fea + ' : finish!!!')\n",
    "        train_df = train_temp_df\n",
    "        train_df.sort_index(by='index', ascending=True, inplace=True)\n",
    "    return train_df, valid_df\n",
    "    \n",
    "fea_set = ['prefix', 'title', 'tag', 'query_prediction']\n",
    "train_df, test_df = get_single_dimension_rate_feature(train_df, test_df, fea_set)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix_title : finish!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix_tag : finish!!!\n",
      "title_tag : finish!!!\n",
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "0      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "0      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "0      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "1      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "0  HCG大于1368%2C正常吗  健康      0   \n",
      "0            1368年  百科      1   \n",
      "0         银耳红枣汤的做法  菜谱      1   \n",
      "1         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "0  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "0  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "0  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "1  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "0  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "0  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "0  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "1  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "0  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "0  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "0  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "1  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "            ...            query_prediction_click_number  prefix_title_count  \\\n",
      "0           ...                                     40.0                63.0   \n",
      "0           ...                                      1.0                 NaN   \n",
      "0           ...                                      0.0                 NaN   \n",
      "0           ...                                    176.0               155.0   \n",
      "1           ...                                     58.0                57.0   \n",
      "\n",
      "   prefix_title_rate  prefix_title_click_number  prefix_tag_count  \\\n",
      "0           0.333478                       21.0              34.0   \n",
      "0                NaN                        NaN               NaN   \n",
      "0                NaN                        NaN               NaN   \n",
      "0           0.664084                      103.0             155.0   \n",
      "1           0.473283                       27.0              57.0   \n",
      "\n",
      "   prefix_tag_rate  prefix_tag_click_number  title_tag_count  title_tag_rate  \\\n",
      "0         0.033502                      1.0             34.0        0.031736   \n",
      "0              NaN                      NaN              NaN             NaN   \n",
      "0              NaN                      NaN              NaN             NaN   \n",
      "0         0.663779                    103.0            164.0        0.652048   \n",
      "1         0.473028                     27.0             64.0        0.515125   \n",
      "\n",
      "   title_tag_click_number  \n",
      "0                     1.0  \n",
      "0                     NaN  \n",
      "0                     NaN  \n",
      "0                   107.0  \n",
      "1                    33.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计双维度交叉转化率\n",
    "def get_jiaocha_dimension_rate_feature(train_df, valid_df, fea_set):\n",
    "    for i in range(len(fea_set)):\n",
    "        for j in range((i+1), len(fea_set)):\n",
    "            fea1 = fea_set[i]\n",
    "            fea2 = fea_set[j]\n",
    "            train_temp_df = pd.DataFrame()\n",
    "            for index, (train_index, test_index) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "                temp_df = train_df[[fea1, fea2, 'label']].iloc[train_index].copy()\n",
    "                temp_pivot_table = pd.pivot_table(temp_df, index=[fea1, fea2], values='label', aggfunc={len, np.mean, np.sum})\n",
    "                temp_pivot_table.reset_index(inplace=True)\n",
    "                temp_pivot_table.rename(columns={'len':fea1 + '_' + fea2 + '_count', 'mean':fea1 + '_' + fea2 + '_rate', 'sum':fea1 + '_' + fea2 + '_click_number'}, inplace=True)\n",
    "                alpha, beta = getBayesSmoothParam(temp_pivot_table[fea1 + '_' + fea2 + '_rate'])\n",
    "                temp_pivot_table[fea1 + '_' + fea2 + '_rate'] = (temp_pivot_table[fea1 + '_' + fea2 + '_click_number'] + alpha) / (temp_pivot_table[fea1 + '_' + fea2 + '_count'] + alpha + beta)\n",
    "#                 del temp_pivot_table[fea1 + '_' + fea2 + '_click_number']\n",
    "                fea_df = train_df.iloc[test_index].copy()\n",
    "                fea_df = pd.merge(fea_df, temp_pivot_table, on=[fea1, fea2], how='left')\n",
    "                train_temp_df = pd.concat([train_temp_df, fea_df])\n",
    "            temp_df = train_df[[fea1, fea2, 'label']].copy()\n",
    "            temp_pivot_table = pd.pivot_table(temp_df, index=[fea1, fea2], values='label', aggfunc={len, np.mean, np.sum})\n",
    "            temp_pivot_table.reset_index(inplace=True)\n",
    "            temp_pivot_table.rename(columns={'len':fea1 + '_' + fea2 + '_count', 'mean':fea1 + '_' + fea2 + '_rate', 'sum':fea1 + '_' + fea2 + '_click_number'}, inplace=True)\n",
    "            alpha, beta = getBayesSmoothParam(temp_pivot_table[fea1 + '_' + fea2 + '_rate'])\n",
    "            temp_pivot_table[fea1 + '_' + fea2 + '_rate'] = (temp_pivot_table[fea1 + '_' + fea2 + '_click_number'] + alpha) / (temp_pivot_table[fea1 + '_' + fea2 + '_count'] + alpha + beta)\n",
    "#             del temp_pivot_table[fea1 + '_' + fea2 + '_click_number']\n",
    "            print(fea1 + '_' + fea2 + ' : finish!!!')\n",
    "            valid_df = pd.merge(valid_df, temp_pivot_table, on=[fea1, fea2], how='left')\n",
    "            train_df = train_temp_df\n",
    "            train_df.sort_index(by='index', ascending=True, inplace=True)\n",
    "    return train_df, valid_df\n",
    "\n",
    "jiaocha_fea_set = ['prefix', 'title', 'tag']\n",
    "train_df, test_df = get_jiaocha_dimension_rate_feature(train_df, test_df, jiaocha_fea_set)\n",
    "print(train_df.head())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计一些是否交叉的特征\n",
    "def get_is_title_in_query_feature(df):\n",
    "    x = df['title']\n",
    "    y = df['query_prediction_keys']\n",
    "    is_title_in_query = np.nan\n",
    "    if len(y) > 0:\n",
    "        if x in y:\n",
    "            is_title_in_query = 1\n",
    "        else:\n",
    "            is_title_in_query = 0\n",
    "    return is_title_in_query\n",
    "\n",
    "def get_is_prefix_in_title_feature(df):\n",
    "    x = df['prefix']\n",
    "    y = df['title']\n",
    "    is_prefix_in_title = np.nan\n",
    "    if x in y:\n",
    "        is_prefix_in_title = 1\n",
    "    else:\n",
    "        is_prefix_in_title = 0\n",
    "    return is_prefix_in_title\n",
    "\n",
    "train_df['is_title_in_query'] = train_df[['title', 'query_prediction_keys']].apply(get_is_title_in_query_feature, axis = 1)\n",
    "test_df['is_title_in_query'] = test_df[['title', 'query_prediction_keys']].apply(get_is_title_in_query_feature, axis = 1)\n",
    "\n",
    "train_df['is_prefix_in_title'] = train_df[['prefix', 'title']].apply(get_is_prefix_in_title_feature, axis = 1)\n",
    "test_df['is_prefix_in_title'] = test_df[['prefix', 'title']].apply(get_is_prefix_in_title_feature, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "               ...               is_title_in_query  is_prefix_in_title  \\\n",
      "0              ...                             0.0                   1   \n",
      "1              ...                             0.0                   1   \n",
      "2              ...                             1.0                   1   \n",
      "3              ...                             0.0                   1   \n",
      "4              ...                             1.0                   1   \n",
      "\n",
      "   title_tag_types  prefix_tag_types  tag_title_types  tag_prefix_types  \\\n",
      "0                2                 3            18119             17476   \n",
      "1                1                 2            45856             39455   \n",
      "2                1                 2           129054            109670   \n",
      "3                1                 4            12741             11493   \n",
      "4                2                 3           129054            109670   \n",
      "\n",
      "   title_prefix_types  prefix_title_types  tag_query_prediction_types  \\\n",
      "0                   1                   2                       17299   \n",
      "1                   1                   2                       37560   \n",
      "2                   1                   2                      107556   \n",
      "3                   4                   4                       11364   \n",
      "4                   4                   3                      107556   \n",
      "\n",
      "   title_query_prediction_types  \n",
      "0                             1  \n",
      "1                             1  \n",
      "2                             1  \n",
      "3                             4  \n",
      "4                             4  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计一些交叉种类特征\n",
    "def get_jiaocha_type_feature(train_df, valid_df, jiaocha_type_list):\n",
    "    for jiaocha_type in jiaocha_type_list:\n",
    "        fea1 = jiaocha_type[0]\n",
    "        fea2 = jiaocha_type[1]\n",
    "        temp_df = pd.concat([train_df, valid_df])\n",
    "        temp_pivot_table = pd.pivot_table(temp_df[[fea1, fea2, 'label']], index=[fea1, fea2], values='label', aggfunc=len)\n",
    "        temp_pivot_table.reset_index(inplace=True)\n",
    "        final_pivot_table = pd.pivot_table(temp_pivot_table, index=fea1, values=fea2, aggfunc=len)\n",
    "        final_pivot_table.reset_index(inplace=True)\n",
    "        final_pivot_table.rename(columns={fea2 : fea1 + '_' + fea2 + '_types'}, inplace=True)\n",
    "        train_df = pd.merge(train_df, final_pivot_table[[fea1, fea1 + '_' + fea2 + '_types']], on=fea1, how='left')\n",
    "        valid_df = pd.merge(valid_df, final_pivot_table[[fea1, fea1 + '_' + fea2 + '_types']], on=fea1, how='left')\n",
    "    return train_df, valid_df\n",
    "\n",
    "jiaocha_type_list = [['title', 'tag'], ['prefix', 'tag'], ['tag', 'title'], ['tag', 'prefix'], \n",
    "                     ['title', 'prefix'], ['prefix', 'title'], ['tag', 'query_prediction'], ['title', 'query_prediction']]\n",
    "train_df, test_df = get_jiaocha_type_feature(train_df, test_df, jiaocha_type_list)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "        ...        prefix_len  title_len  query_prediction_key_len_max  \\\n",
      "0       ...                 2          2                          10.0   \n",
      "1       ...                 4         15                          15.0   \n",
      "2       ...                 4          5                          15.0   \n",
      "3       ...                 2          8                          10.0   \n",
      "4       ...                 4          8                          10.0   \n",
      "\n",
      "   query_prediction_key_len_min  query_prediction_key_len_mean  \\\n",
      "0                           4.0                       5.600000   \n",
      "1                           5.0                       9.222222   \n",
      "2                           5.0                       9.222222   \n",
      "3                           3.0                       5.700000   \n",
      "4                           6.0                       7.900000   \n",
      "\n",
      "   query_prediction_key_len_std  len_title-prefix  len_prefix/title  \\\n",
      "0                      2.009975                 0          1.000000   \n",
      "1                      3.010270                11          0.266667   \n",
      "2                      3.010270                 1          0.800000   \n",
      "3                      1.734935                 6          0.250000   \n",
      "4                      1.300000                 4          0.500000   \n",
      "\n",
      "   len_mean-title  len_mean/title  \n",
      "0        3.600000        2.800000  \n",
      "1       -5.777778        0.614815  \n",
      "2        4.222222        1.844444  \n",
      "3       -2.300000        0.712500  \n",
      "4       -0.100000        0.987500  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_key_len_list(x):\n",
    "    return_list = []\n",
    "    for temp in x:\n",
    "        return_list.append(len(temp))\n",
    "    return return_list\n",
    "\n",
    "# 统计一些跟字符串长度相关的特征\n",
    "def get_string_len_feature(df):\n",
    "    df['prefix_len'] = df['prefix'].map(lambda x : len(x))\n",
    "    df['title_len'] = df['title'].map(lambda x : len(x))\n",
    "    df['query_prediction_key_len_list'] = df['query_prediction_keys'].map(lambda x : get_key_len_list(x))\n",
    "    df['query_prediction_key_len_max'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.max(x))\n",
    "    df['query_prediction_key_len_min'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.min(x))\n",
    "    df['query_prediction_key_len_mean'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.mean(x))\n",
    "    df['query_prediction_key_len_std'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.std(x))\n",
    "    df['len_title-prefix'] = df['title_len'] - df['prefix_len']\n",
    "    df['len_prefix/title'] = df['prefix_len'] / df['title_len']\n",
    "    df['len_mean-title'] = df['query_prediction_key_len_mean'] - df['title_len']\n",
    "    df['len_mean/title'] = df['query_prediction_key_len_mean'] / df['title_len']\n",
    "    del df['query_prediction_key_len_list']\n",
    "    return df\n",
    "\n",
    "train_df = get_string_len_feature(train_df)\n",
    "test_df = get_string_len_feature(test_df)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "            ...             query_prediction_key_len_max  \\\n",
      "0           ...                                     10.0   \n",
      "1           ...                                     15.0   \n",
      "2           ...                                     15.0   \n",
      "3           ...                                     10.0   \n",
      "4           ...                                     10.0   \n",
      "\n",
      "   query_prediction_key_len_min  query_prediction_key_len_mean  \\\n",
      "0                           4.0                       5.600000   \n",
      "1                           5.0                       9.222222   \n",
      "2                           5.0                       9.222222   \n",
      "3                           3.0                       5.700000   \n",
      "4                           6.0                       7.900000   \n",
      "\n",
      "   query_prediction_key_len_std  len_title-prefix  len_prefix/title  \\\n",
      "0                      2.009975                 0          1.000000   \n",
      "1                      3.010270                11          0.266667   \n",
      "2                      3.010270                 1          0.800000   \n",
      "3                      1.734935                 6          0.250000   \n",
      "4                      1.300000                 4          0.500000   \n",
      "\n",
      "   len_mean-title  len_mean/title  title_prefix_leven  title_prefix_leven_rate  \n",
      "0        3.600000        2.800000                   0                 0.000000  \n",
      "1       -5.777778        0.614815                  11                 0.611111  \n",
      "2        4.222222        1.844444                   1                 0.125000  \n",
      "3       -2.300000        0.712500                   6                 0.545455  \n",
      "4       -0.100000        0.987500                   4                 0.363636  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计title跟prefix的编辑距离\n",
    "def get_title_prefix_levenshtein_distance(df):\n",
    "    title = df['title']\n",
    "    prefix = df['prefix']\n",
    "    return Levenshtein.distance(title, prefix)\n",
    "\n",
    "def get_title_prefix_levenshtein_distance_rate(df):\n",
    "    title_prefix_leven = df['title_prefix_leven']\n",
    "    title = df['title']\n",
    "    return (title_prefix_leven / (len(title) + 3))\n",
    "\n",
    "train_df['title_prefix_leven'] = train_df[['title', 'prefix']].apply(get_title_prefix_levenshtein_distance, axis=1)\n",
    "test_df['title_prefix_leven'] = test_df[['title', 'prefix']].apply(get_title_prefix_levenshtein_distance, axis=1)\n",
    "\n",
    "train_df['title_prefix_leven_rate'] = train_df[['title', 'title_prefix_leven']].apply(get_title_prefix_levenshtein_distance_rate, axis=1)\n",
    "test_df['title_prefix_leven_rate'] = test_df[['title', 'title_prefix_leven']].apply(get_title_prefix_levenshtein_distance_rate, axis=1)\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "           ...            len_mean-title  len_mean/title  title_prefix_leven  \\\n",
      "0          ...                  3.600000        2.800000                   0   \n",
      "1          ...                 -5.777778        0.614815                  11   \n",
      "2          ...                  4.222222        1.844444                   1   \n",
      "3          ...                 -2.300000        0.712500                   6   \n",
      "4          ...                 -0.100000        0.987500                   4   \n",
      "\n",
      "   title_prefix_leven_rate                             title_query_leven_list  \\\n",
      "0                 0.000000  [0.045, 0.024, 0.04, 0.264, 0.021, 0.06, 0.396...   \n",
      "1                 0.611111  [0.649, 1.488, 0.319, 0.77, 0.242, 0.504, 0.94...   \n",
      "2                 0.125000  [0.354, 0.868, 0.08700000000000001, 0.42000000...   \n",
      "3                 0.545455  [0.048, 0.072, 0.30000000000000004, 0.135, 0.2...   \n",
      "4                 0.363636  [0.06, 0.016, 0.018, 0.036, 2.276, 0.064, 0.08...   \n",
      "\n",
      "   title_query_leven_sum  title_query_leven_max  title_query_leven_min  \\\n",
      "0                  1.054                  0.396                  0.020   \n",
      "1                  5.978                  1.488                  0.242   \n",
      "2                  2.623                  0.868                  0.000   \n",
      "3                  1.590                  0.342                  0.048   \n",
      "4                  2.672                  2.276                  0.000   \n",
      "\n",
      "   title_query_leven_mean  title_query_leven_std  \n",
      "0                0.105400               0.120359  \n",
      "1                0.664222               0.364696  \n",
      "2                0.291444               0.248284  \n",
      "3                0.159000               0.103037  \n",
      "4                0.267200               0.670101  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计title跟query_prediction编辑距离相关的特征\n",
    "def get_title_query_levenshtein_distance_list(df):\n",
    "    query_keys_list = df['query_prediction_keys']\n",
    "    query_values_list = df['query_prediction_values']\n",
    "    title = df['title']\n",
    "    return_list = list()\n",
    "    for i in range(len(query_keys_list)):\n",
    "        distance = Levenshtein.distance(title, query_keys_list[i])\n",
    "        return_list.append(distance * query_values_list[i])\n",
    "    return return_list\n",
    "\n",
    "def get_title_query_levenshtein_distance_feature(df):\n",
    "    df['title_query_leven_list'] = df[['query_prediction_keys', 'query_prediction_values', 'title']].apply(get_title_query_levenshtein_distance_list, axis=1)\n",
    "    df['title_query_leven_sum'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.sum(x))\n",
    "    df['title_query_leven_max'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.max(x))\n",
    "    df['title_query_leven_min'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.min(x))\n",
    "    df['title_query_leven_mean'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.mean(x))\n",
    "    df['title_query_leven_std'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.std(x))\n",
    "    return df\n",
    "\n",
    "train_df = get_title_query_levenshtein_distance_feature(train_df)\n",
    "test_df = get_title_query_levenshtein_distance_feature(test_df)\n",
    "print(train_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/jieba/__init__.py\", line 152, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmpno47h46t' -> '/tmp/jieba.cache'\n",
      "Loading model cost 1.131 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "          ...          title_query_leven_sum  title_query_leven_max  \\\n",
      "0         ...                          1.054                  0.396   \n",
      "1         ...                          5.978                  1.488   \n",
      "2         ...                          2.623                  0.868   \n",
      "3         ...                          1.590                  0.342   \n",
      "4         ...                          2.672                  2.276   \n",
      "\n",
      "   title_query_leven_min  title_query_leven_mean  title_query_leven_std  \\\n",
      "0                  0.020                0.105400               0.120359   \n",
      "1                  0.242                0.664222               0.364696   \n",
      "2                  0.000                0.291444               0.248284   \n",
      "3                  0.048                0.159000               0.103037   \n",
      "4                  0.000                0.267200               0.670101   \n",
      "\n",
      "                      query_prediction_key_sentences  \\\n",
      "0  小品大全宋小宝小品相亲小品剧本小品搞笑大全小品不差钱小品搞笑大全剧本小品大全小品演员小品视频...   \n",
      "1  13688cc赛马会1368536789213688cc1368个单词就够了1368e136...   \n",
      "2  13688cc赛马会1368536789213688cc1368个单词就够了1368e136...   \n",
      "3  银耳汤的功效银耳为什么不能天天吃银耳莲子羹银耳的做法银耳的功效银耳莲子汤银耳汤的做法银耳红枣...   \n",
      "4  月经量少喝红糖水好吗月经量少该怎么调理月经量少怎么月经量少发黑月经量少是什么原因月经量少吃什...   \n",
      "\n",
      "                    query_prediction_key_jieba_words  \\\n",
      "0  [小品, 大全, 宋, 小宝, 小品, 相亲, 小品, 剧本, 小品, 搞笑, 大全, 小品...   \n",
      "1  [13688cc, 赛马会, 1368536789213688cc1368, 个, 单词, ...   \n",
      "2  [13688cc, 赛马会, 1368536789213688cc1368, 个, 单词, ...   \n",
      "3  [银耳汤, 的, 功效, 银耳, 为什么, 不能, 天天, 吃, 银耳, 莲子, 羹, 银耳...   \n",
      "4  [月经, 量少, 喝, 红糖, 水好, 吗, 月经, 量少, 该, 怎么, 调理, 月经, ...   \n",
      "\n",
      "                              query_prediction_words  \\\n",
      "0  [[小品, 大全, 宋, 小宝], [小品, 相亲], [小品, 剧本], [小品, 搞笑,...   \n",
      "1  [[13688cc, 赛马会], [13685367892], [13688cc], [13...   \n",
      "2  [[13688cc, 赛马会], [13685367892], [13688cc], [13...   \n",
      "3  [[银耳汤, 的, 功效], [银耳, 为什么, 不能, 天天, 吃], [银耳, 莲子, ...   \n",
      "4  [[月经, 量少, 喝, 红糖, 水好, 吗], [月经, 量少, 该, 怎么, 调理], ...   \n",
      "\n",
      "             title_jieba_words  prefix_jieba_words  \n",
      "0                         [小品]                [小品]  \n",
      "1  [HCG, 大于, 1368%, 2C, 正常, 吗]              [1368]  \n",
      "2                    [1368, 年]              [1368]  \n",
      "3             [银耳, 红枣汤, 的, 做法]                [银耳]  \n",
      "4             [月经, 量少, 怎么, 调理]            [月经, 量少]  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "#分词方法，调用结巴接口\n",
    "def jieba_seg_to_list(sentence, pos=False):\n",
    "    if not pos:\n",
    "        #不进行词性标注的分词方法\n",
    "        seg_list = jieba.cut(sentence)\n",
    "    else:\n",
    "        #进行词性标注的分词方法\n",
    "        seg_list = psg.cut(sentence)\n",
    "    return seg_list\n",
    "\n",
    "#去除干扰词\n",
    "def jieba_word_filter(seg_list, pos=False):\n",
    "    \n",
    "    filter_list = []\n",
    "    #根据pos参数选择是否词性过滤\n",
    "    #不进行词性过滤，则将词性都标记为n，表示全部保留\n",
    "    for seg in seg_list:\n",
    "        if not pos:\n",
    "            word = seg\n",
    "            flag = 'n'\n",
    "        else:\n",
    "            word = seg.word\n",
    "            flag = seg.flag\n",
    "        if not flag.startswith('n'):\n",
    "            continue\n",
    "        filter_list.append(word)\n",
    "    return filter_list\n",
    "\n",
    "def jieba_word_deal(sentence, pos=False):\n",
    "    #调用上面方式对数据集进行处理，处理后的每条数据仅保留非干扰词\n",
    "    seg_list = jieba_seg_to_list(sentence, pos)\n",
    "    filter_list = jieba_word_filter(seg_list, pos)\n",
    "    return filter_list\n",
    "\n",
    "def get_prefix_prediction_key_sentences(x):\n",
    "    prefix_prediction_key_sentences = \"\"\n",
    "    for temp in x:\n",
    "        if len(prefix_prediction_key_sentences) > 0:\n",
    "            prefix_prediction_key_sentences = prefix_prediction_key_sentences + temp\n",
    "        else:\n",
    "            prefix_prediction_key_sentences = temp\n",
    "    return prefix_prediction_key_sentences\n",
    "\n",
    "def get_max_query_key_sentences(x):\n",
    "    if len(x) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return max(x, key=x.get)\n",
    "\n",
    "def get_jieba_word(df):\n",
    "    df['query_prediction_key_sentences'] = df['query_prediction_keys'].map(lambda x : get_prefix_prediction_key_sentences(x))\n",
    "#     df['query_prediction_key_sentences'] = df['query_prediction_dict'].map(lambda x : get_max_query_key_sentences(x))\n",
    "    df['query_prediction_key_jieba_words'] = df['query_prediction_key_sentences'].map(lambda x : jieba_word_deal(x, False))\n",
    "    df['query_prediction_words'] = df['query_prediction_keys'].map(lambda x : [jieba_word_deal(j, False) for j in x] if len(x) > 0 else np.nan)\n",
    "    df['title_jieba_words'] = df['title'].map(lambda x : jieba_word_deal(x, False))\n",
    "    df['prefix_jieba_words'] = df['prefix'].map(lambda x : jieba_word_deal(x, False))\n",
    "#     del df['query_prediction_key_sentences']\n",
    "    return df\n",
    "\n",
    "train_df = get_jieba_word(train_df)\n",
    "test_df = get_jieba_word(test_df)\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_t_word_match finish!!!\n",
      "q_t_jaccard finish!!!\n",
      "q_t_common_words finish!!!\n",
      "q_t_total_unique_words finish!!!\n",
      "q_t_wc_diff finish!!!\n",
      "q_t_wc_ratio finish!!!\n",
      "q_t_wc_diff_unique finish!!!\n",
      "q_t_wc_ratio_unique finish!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_t_tfidf_word_match_share finish!!!\n",
      "p_t_word_match finish!!!\n",
      "p_t_jaccard finish!!!\n",
      "p_t_common_words finish!!!\n",
      "p_t_total_unique_words finish!!!\n",
      "p_t_wc_diff finish!!!\n",
      "p_t_wc_ratio finish!!!\n",
      "p_t_wc_diff_unique finish!!!\n",
      "p_t_wc_ratio_unique finish!!!\n",
      "p_t_tfidf_word_match_share finish!!!\n",
      "p_q_word_match finish!!!\n",
      "p_q_jaccard finish!!!\n",
      "p_q_common_words finish!!!\n",
      "p_q_total_unique_words finish!!!\n",
      "p_q_wc_diff finish!!!\n",
      "p_q_wc_ratio finish!!!\n",
      "p_q_wc_diff_unique finish!!!\n",
      "p_q_wc_ratio_unique finish!!!\n",
      "p_q_tfidf_word_match_share finish!!!\n",
      "   index prefix                                   query_prediction  \\\n",
      "0      0     小品  {\"小品大全宋小宝\": \"0.009\", \"小品相亲\": \"0.012\", \"小品剧本\": ...   \n",
      "1      1   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "2      2   1368  {\"13688cc赛马会\": \"0.059\", \"13685367892\": \"0.124\"...   \n",
      "3      3     银耳  {\"银耳汤的功效\": \"0.012\", \"银耳为什么不能天天吃\": \"0.009\", \"银耳...   \n",
      "4      4   月经量少  {\"月经量少喝红糖水好吗\": \"0.010\", \"月经量少该怎么调理\": \"0.016\", ...   \n",
      "\n",
      "             title tag  label  \\\n",
      "0               小品  阅读      0   \n",
      "1  HCG大于1368%2C正常吗  健康      0   \n",
      "2            1368年  百科      1   \n",
      "3         银耳红枣汤的做法  菜谱      1   \n",
      "4         月经量少怎么调理  百科      0   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'小品大全宋小宝': '0.009', '小品相亲': '0.012', '小品剧本': ...   \n",
      "1  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "2  {'13688cc赛马会': '0.059', '13685367892': '0.124'...   \n",
      "3  {'银耳汤的功效': '0.012', '银耳为什么不能天天吃': '0.009', '银耳...   \n",
      "4  {'月经量少喝红糖水好吗': '0.010', '月经量少该怎么调理': '0.016', ...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [小品大全宋小宝, 小品相亲, 小品剧本, 小品搞笑大全, 小品不差钱, 小品搞笑大全剧本,...   \n",
      "1  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "2  [13688cc赛马会, 13685367892, 13688cc, 1368个单词就够了,...   \n",
      "3  [银耳汤的功效, 银耳为什么不能天天吃, 银耳莲子羹, 银耳的做法, 银耳的功效, 银耳莲子...   \n",
      "4  [月经量少喝红糖水好吗, 月经量少该怎么调理, 月经量少怎么, 月经量少发黑, 月经量少是什...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.009, 0.012, 0.02, 0.066, 0.007, 0.01, 0.198...                       10   \n",
      "1  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "2  [0.059, 0.124, 0.029, 0.07, 0.022, 0.042, 0.08...                        9   \n",
      "3  [0.012, 0.009, 0.05, 0.045, 0.053, 0.014, 0.05...                       10   \n",
      "4  [0.01, 0.016, 0.009, 0.009, 0.569, 0.016, 0.02...                       10   \n",
      "\n",
      "              ...              p_t_tfidf_word_match_share  p_q_word_match  \\\n",
      "0             ...                                1.000000        0.153846   \n",
      "1             ...                                0.000000        0.000000   \n",
      "2             ...                                0.899648        0.000000   \n",
      "3             ...                                0.531426        0.133333   \n",
      "4             ...                                0.813111        0.222222   \n",
      "\n",
      "   p_q_jaccard  p_q_common_words  p_q_total_unique_words  p_q_wc_diff  \\\n",
      "0     0.083333                 1                      12           28   \n",
      "1     0.000000                 0                      15           13   \n",
      "2     0.000000                 0                      15           13   \n",
      "3     0.071429                 1                      14           28   \n",
      "4     0.125000                 2                      16           41   \n",
      "\n",
      "   p_q_wc_ratio  p_q_wc_diff_unique  p_q_wc_ratio_unique  \\\n",
      "0          29.0                  11                 12.0   \n",
      "1          14.0                  13                 14.0   \n",
      "2          14.0                  13                 14.0   \n",
      "3          29.0                  13                 14.0   \n",
      "4          21.5                  14                  8.0   \n",
      "\n",
      "   p_q_tfidf_word_match_share  \n",
      "0                    0.176562  \n",
      "1                    0.000000  \n",
      "2                    0.000000  \n",
      "3                    0.176915  \n",
      "4                    0.284081  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "def word_match_share(df):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in df[0]:\n",
    "        q1words[word] = 1\n",
    "    for word in df[1]:\n",
    "        q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "def jaccard(df):\n",
    "    wic = set(df[0]).intersection(set(df[1]))\n",
    "    uw = set(df[0]).union(df[1])\n",
    "    if len(uw) == 0:\n",
    "        uw = [1]\n",
    "    return (len(wic) / len(uw))\n",
    "\n",
    "def common_words(df):\n",
    "    return len(set(df[0]).intersection(set(df[1])))\n",
    "\n",
    "def total_unique_words(df):\n",
    "    return len(set(df[0]).union(df[1]))\n",
    "\n",
    "def wc_diff(df):\n",
    "    return abs(len(df[0]) - len(df[1]))\n",
    "\n",
    "def wc_ratio(df):\n",
    "    l1 = len(df[0])*1.0 \n",
    "    l2 = len(df[1])\n",
    "    if l2 == 0:\n",
    "        return np.nan\n",
    "    if l1 / l2:\n",
    "        return l2 / l1\n",
    "    else:\n",
    "        return l1 / l2\n",
    "\n",
    "def wc_diff_unique(df):\n",
    "    return abs(len(set(df[0])) - len(set(df[1])))\n",
    "    \n",
    "def wc_ratio_unique(df):\n",
    "    l1 = len(set(df[0])) * 1.0\n",
    "    l2 = len(set(df[1]))\n",
    "    if l2 == 0:\n",
    "        return np.nan\n",
    "    if l1 / l2:\n",
    "        return l2 / l1\n",
    "    else:\n",
    "        return l1 / l2\n",
    "    \n",
    "def tfidf_word_match_share(df, weights=None):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in df[0]:\n",
    "        q1words[word] = 1\n",
    "    for word in df[1]:\n",
    "        q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R\n",
    "\n",
    "def deal_word_for_all(train_df, valid_df, fea1, fea2, func, colName):\n",
    "    train_df[colName] = train_df[[fea1, fea2]].apply(func, axis=1)\n",
    "    valid_df[colName] = valid_df[[fea1, fea2]].apply(func, axis=1)\n",
    "    print(colName + ' finish!!!')\n",
    "    return train_df, valid_df\n",
    "                   \n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "\n",
    "def get_word_statistic_feature(train_df, valid_df, col_list):\n",
    "    df = pd.concat([train_df[['query_prediction_key_jieba_words', 'title_jieba_words', 'prefix_jieba_words']], valid_df[['query_prediction_key_jieba_words', 'title_jieba_words', 'prefix_jieba_words']]])\n",
    "    train_qs = pd.Series(df['query_prediction_key_jieba_words'].tolist() + df['title_jieba_words'].tolist() + df['prefix_jieba_words'].tolist())\n",
    "    words = [x for y in train_qs for x in y]\n",
    "    counts = Counter(words)\n",
    "    weights = {word: get_weight(count) for word, count in counts.items()}\n",
    "    for col in col_list:\n",
    "        fea1 = col[0]\n",
    "        fea2 = col[1]\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, word_match_share, fea1[0] + '_' + fea2[0] + '_word_match')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, jaccard, fea1[0] + '_' + fea2[0] + '_jaccard')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, common_words, fea1[0] + '_' + fea2[0] + '_common_words')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, total_unique_words, fea1[0] + '_' + fea2[0] + '_total_unique_words')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_diff, fea1[0] + '_' + fea2[0] + '_wc_diff')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_ratio, fea1[0] + '_' + fea2[0] + '_wc_ratio')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_diff_unique, fea1[0] + '_' + fea2[0] + '_wc_diff_unique')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_ratio_unique, fea1[0] + '_' + fea2[0] + '_wc_ratio_unique')\n",
    "        f = functools.partial(tfidf_word_match_share, weights=weights)\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, f, fea1[0] + '_' + fea2[0] + '_tfidf_word_match_share')\n",
    "    return train_df, valid_df\n",
    "\n",
    "col_list = [['query_prediction_key_jieba_words', 'title_jieba_words'], ['prefix_jieba_words', 'title_jieba_words'], ['prefix_jieba_words', 'query_prediction_key_jieba_words']]\n",
    "train_df, test_df = get_word_statistic_feature(train_df, test_df, col_list)\n",
    "print(train_df.head())\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 500  # Word vector dimensionality                      \n",
    "min_word_count = 1  # Minimum word count                        \n",
    "num_workers = 20       # Number of threads to run in parallel\n",
    "context = 5          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "word2vec_df = pd.concat([train_df[['query_prediction_words', 'title_jieba_words', 'prefix_jieba_words', 'query_prediction_number']], test_df[['query_prediction_words', 'title_jieba_words', 'prefix_jieba_words', 'query_prediction_number']]])\n",
    "word2vec_df.reset_index(inplace=True)\n",
    "word2vec_list = word2vec_df['title_jieba_words'].tolist() + word2vec_df['prefix_jieba_words'].tolist() + [y for x in word2vec_df['query_prediction_words'][word2vec_df.query_prediction_number > 0] for y in x]\n",
    "model = word2vec.Word2Vec(word2vec_list, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "word_wv = model.wv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_w2v_array(word_list, word_wv, num_features):\n",
    "    word_vectors = np.zeros((len(word_list), num_features))\n",
    "    for i in range(len(word_list)):\n",
    "        word_vectors[i][:] = word_wv[str(word_list[i])]\n",
    "    mean_array = np.mean(word_vectors, axis=0)\n",
    "    return mean_array\n",
    "\n",
    "train_df['title_jieba_array'] = train_df['title_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "test_df['title_jieba_array'] = test_df['title_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "\n",
    "train_df['prefix_jieba_array'] = train_df['prefix_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "test_df['prefix_jieba_array'] = test_df['prefix_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot : finish!!!\n",
      "norm : finish!!!\n",
      "cosine : finish!!!\n"
     ]
    }
   ],
   "source": [
    "def get_title_prefix_similarity(df, f_similarity):\n",
    "    title_array = df['title_jieba_array']\n",
    "    prefix_array = df['prefix_jieba_array']\n",
    "    similarity = 0\n",
    "    if f_similarity == 'dot':\n",
    "        similarity = np.dot(title_array, prefix_array)\n",
    "    elif f_similarity == 'norm':\n",
    "        similarity = np.linalg.norm(title_array - prefix_array)\n",
    "    else:\n",
    "        similarity = np.dot(title_array,prefix_array) / (np.linalg.norm(title_array) * np.linalg.norm(prefix_array))\n",
    "    return similarity\n",
    "\n",
    "# def get_title_query_similarity(df, f_similarity, word_wv, num_features):\n",
    "#     title_array = df['title_jieba_array']\n",
    "#     query_prediction_words = df['query_prediction_words']\n",
    "#     query_prediction_keys = df['query_prediction_keys']\n",
    "#     query_prediction_dict = df['query_prediction_dict']\n",
    "#     if len(query_prediction_keys) <= 0:\n",
    "#         return np.nan\n",
    "#     similarity = 0\n",
    "#     if f_similarity == 'dot':\n",
    "#         i = 0\n",
    "#         for key in query_prediction_keys:\n",
    "#             key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "#             similarity = similarity + np.dot(title_array, key_array) * float(query_prediction_dict[key])\n",
    "#             i = i + 1\n",
    "#     elif f_similarity == 'norm':\n",
    "#         i = 0\n",
    "#         for key in query_prediction_keys:\n",
    "#             key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "#             similarity = similarity + np.linalg.norm(title_array - key_array) * float(query_prediction_dict[key])\n",
    "#             i = i + 1\n",
    "#     else:\n",
    "#         i = 0\n",
    "#         for key in query_prediction_keys:\n",
    "#             key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "#             similarity = similarity + (np.dot(title_array, key_array) / (np.linalg.norm(title_array) * np.linalg.norm(key_array))) * float(query_prediction_dict[key])\n",
    "#             i = i + 1\n",
    "#     return similarity\n",
    "\n",
    "def get_title_query_similarity_list(df, f_similarity, word_wv, num_features):\n",
    "    title_array = df['title_jieba_array']\n",
    "    query_prediction_words = df['query_prediction_words']\n",
    "    query_prediction_keys = df['query_prediction_keys']\n",
    "    query_prediction_dict = df['query_prediction_dict']\n",
    "    similarity_list = list()\n",
    "    if len(query_prediction_keys) <= 0:\n",
    "        return similarity_list\n",
    "    if f_similarity == 'dot':\n",
    "        i = 0\n",
    "        for key in query_prediction_keys:\n",
    "            key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "            similarity = np.dot(title_array, key_array) * float(query_prediction_dict[key])\n",
    "            similarity_list.append(similarity)\n",
    "            i = i + 1\n",
    "    elif f_similarity == 'norm':\n",
    "        i = 0\n",
    "        for key in query_prediction_keys:\n",
    "            key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "            similarity = np.linalg.norm(title_array - key_array) * float(query_prediction_dict[key])\n",
    "            similarity_list.append(similarity)\n",
    "            i = i + 1\n",
    "    else:\n",
    "        i = 0\n",
    "        for key in query_prediction_keys:\n",
    "            key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "            similarity = (np.dot(title_array, key_array) / (np.linalg.norm(title_array) * np.linalg.norm(key_array))) * float(query_prediction_dict[key])\n",
    "            similarity_list.append(similarity)\n",
    "            i = i + 1\n",
    "    return similarity_list\n",
    "\n",
    "def get_similarity_feature(train_df, valid_df):\n",
    "    f_list = ['dot', 'norm', 'cosine']\n",
    "    for fun in f_list:\n",
    "        f_prefix_similarity = functools.partial(get_title_prefix_similarity, f_similarity=fun)\n",
    "        train_df['title_prefix_' + fun + '_similarity'] = train_df[['title_jieba_array', 'prefix_jieba_array']].apply(f_prefix_similarity, axis=1)\n",
    "        valid_df['title_prefix_' + fun + '_similarity'] = valid_df[['title_jieba_array', 'prefix_jieba_array']].apply(f_prefix_similarity, axis=1)\n",
    "#         f_query_similarity = functools.partial(get_title_query_similarity, f_similarity=fun, word_wv=word_wv, num_features=num_features)\n",
    "#         train_df['title_query_' + fun + '_similarity'] = train_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity, axis=1)\n",
    "#         valid_df['title_query_' + fun + '_similarity'] = valid_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity, axis=1)\n",
    "        f_query_similarity_list = functools.partial(get_title_query_similarity_list, f_similarity=fun, word_wv=word_wv, num_features=num_features)\n",
    "        train_df['title_query_' + fun + '_similarity_list'] = train_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity_list, axis=1)\n",
    "        valid_df['title_query_' + fun + '_similarity_list'] = valid_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity_list, axis=1)\n",
    "        train_df['title_query_' + fun + '_similarity'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.sum(x))\n",
    "        train_df['title_query_' + fun + '_similarity_max'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.max(x))\n",
    "        train_df['title_query_' + fun + '_similarity_min'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.min(x))\n",
    "        train_df['title_query_' + fun + '_similarity_mean'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.mean(x))\n",
    "        train_df['title_query_' + fun + '_similarity_std'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.std(x))\n",
    "        valid_df['title_query_' + fun + '_similarity'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.sum(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_max'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.max(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_min'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.min(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_mean'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.mean(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_std'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.std(x))\n",
    "        print(fun + ' : finish!!!')\n",
    "    return train_df, valid_df\n",
    "\n",
    "train_df, test_df = get_similarity_feature(train_df, test_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index' 'prefix' 'query_prediction' 'title' 'tag' 'label'\n",
      " 'query_prediction_dict' 'query_prediction_keys' 'query_prediction_values'\n",
      " 'query_prediction_number' 'query_prediction_max' 'query_prediction_min'\n",
      " 'query_prediction_mean' 'query_prediction_std' 'prefix_count'\n",
      " 'prefix_rate' 'prefix_click_number' 'title_count' 'title_rate'\n",
      " 'title_click_number' 'tag_count' 'tag_rate' 'tag_click_number'\n",
      " 'query_prediction_count' 'query_prediction_rate'\n",
      " 'query_prediction_click_number' 'prefix_title_count' 'prefix_title_rate'\n",
      " 'prefix_title_click_number' 'prefix_tag_count' 'prefix_tag_rate'\n",
      " 'prefix_tag_click_number' 'title_tag_count' 'title_tag_rate'\n",
      " 'title_tag_click_number' 'is_title_in_query' 'is_prefix_in_title'\n",
      " 'title_tag_types' 'prefix_tag_types' 'tag_title_types' 'tag_prefix_types'\n",
      " 'title_prefix_types' 'prefix_title_types' 'tag_query_prediction_types'\n",
      " 'title_query_prediction_types' 'prefix_len' 'title_len'\n",
      " 'query_prediction_key_len_max' 'query_prediction_key_len_min'\n",
      " 'query_prediction_key_len_mean' 'query_prediction_key_len_std'\n",
      " 'len_title-prefix' 'len_prefix/title' 'len_mean-title' 'len_mean/title'\n",
      " 'title_prefix_leven' 'title_prefix_leven_rate' 'title_query_leven_list'\n",
      " 'title_query_leven_sum' 'title_query_leven_max' 'title_query_leven_min'\n",
      " 'title_query_leven_mean' 'title_query_leven_std'\n",
      " 'query_prediction_key_sentences' 'query_prediction_key_jieba_words'\n",
      " 'query_prediction_words' 'title_jieba_words' 'prefix_jieba_words'\n",
      " 'q_t_word_match' 'q_t_jaccard' 'q_t_common_words'\n",
      " 'q_t_total_unique_words' 'q_t_wc_diff' 'q_t_wc_ratio'\n",
      " 'q_t_wc_diff_unique' 'q_t_wc_ratio_unique' 'q_t_tfidf_word_match_share'\n",
      " 'p_t_word_match' 'p_t_jaccard' 'p_t_common_words'\n",
      " 'p_t_total_unique_words' 'p_t_wc_diff' 'p_t_wc_ratio'\n",
      " 'p_t_wc_diff_unique' 'p_t_wc_ratio_unique' 'p_t_tfidf_word_match_share'\n",
      " 'p_q_word_match' 'p_q_jaccard' 'p_q_common_words'\n",
      " 'p_q_total_unique_words' 'p_q_wc_diff' 'p_q_wc_ratio'\n",
      " 'p_q_wc_diff_unique' 'p_q_wc_ratio_unique' 'p_q_tfidf_word_match_share'\n",
      " 'title_jieba_array' 'prefix_jieba_array' 'title_prefix_dot_similarity'\n",
      " 'title_query_dot_similarity_list' 'title_query_dot_similarity'\n",
      " 'title_query_dot_similarity_max' 'title_query_dot_similarity_min'\n",
      " 'title_query_dot_similarity_mean' 'title_query_dot_similarity_std'\n",
      " 'title_prefix_norm_similarity' 'title_query_norm_similarity_list'\n",
      " 'title_query_norm_similarity' 'title_query_norm_similarity_max'\n",
      " 'title_query_norm_similarity_min' 'title_query_norm_similarity_mean'\n",
      " 'title_query_norm_similarity_std' 'title_prefix_cosine_similarity'\n",
      " 'title_query_cosine_similarity_list' 'title_query_cosine_similarity'\n",
      " 'title_query_cosine_similarity_max' 'title_query_cosine_similarity_min'\n",
      " 'title_query_cosine_similarity_mean' 'title_query_cosine_similarity_std']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea = [\n",
    "    'query_prediction_number', 'query_prediction_max', 'query_prediction_min', 'query_prediction_mean', 'query_prediction_std',\n",
    "       'prefix_count', 'prefix_rate',\n",
    " 'title_count', 'title_rate', 'tag_count', 'tag_rate',\n",
    " 'query_prediction_count', 'query_prediction_rate', 'prefix_title_count',\n",
    " 'prefix_title_rate',  'prefix_tag_count', 'prefix_tag_rate',\n",
    " 'title_tag_count', 'title_tag_rate',\n",
    "    'prefix_click_number', 'title_click_number', 'query_prediction_click_number', 'prefix_tag_click_number', \n",
    "    'prefix_title_click_number', 'title_tag_click_number',\n",
    "    'is_title_in_query', 'is_prefix_in_title', \n",
    "    'title_tag_types', 'prefix_tag_types', 'tag_title_types', 'tag_prefix_types',\n",
    " 'title_prefix_types', 'prefix_title_types', 'tag_query_prediction_types', 'title_query_prediction_types',\n",
    "      'prefix_len', 'title_len',\n",
    " 'query_prediction_key_len_max', 'query_prediction_key_len_min',\n",
    " 'query_prediction_key_len_mean', 'query_prediction_key_len_std',\n",
    " 'len_title-prefix', 'len_prefix/title', 'len_mean-title', 'len_mean/title',\n",
    "    'q_t_word_match', 'q_t_jaccard', 'q_t_common_words',\n",
    " 'q_t_total_unique_words', 'q_t_wc_diff', 'q_t_wc_ratio',\n",
    " 'q_t_wc_diff_unique', 'q_t_wc_ratio_unique', 'q_t_tfidf_word_match_share',\n",
    " 'p_t_word_match', 'p_t_jaccard', 'p_t_common_words',\n",
    " 'p_t_total_unique_words', 'p_t_wc_diff', 'p_t_wc_ratio',\n",
    " 'p_t_wc_diff_unique', 'p_t_wc_ratio_unique', 'p_t_tfidf_word_match_share',\n",
    " 'p_q_word_match', 'p_q_jaccard', 'p_q_common_words',\n",
    " 'p_q_total_unique_words', 'p_q_wc_diff', 'p_q_wc_ratio',\n",
    " 'p_q_wc_diff_unique', 'p_q_wc_ratio_unique', 'p_q_tfidf_word_match_share',\n",
    "    'title_prefix_dot_similarity',\n",
    " 'title_query_dot_similarity', 'title_prefix_norm_similarity',\n",
    " 'title_query_norm_similarity', 'title_prefix_cosine_similarity',\n",
    " 'title_query_cosine_similarity',\n",
    "    'title_query_dot_similarity_max', 'title_query_dot_similarity_min',\n",
    " 'title_query_dot_similarity_mean', 'title_query_dot_similarity_std',\n",
    "    'title_query_norm_similarity_min', 'title_query_norm_similarity_mean',\n",
    " 'title_query_norm_similarity_std', 'title_prefix_cosine_similarity',\n",
    "    'title_query_cosine_similarity_max', 'title_query_cosine_similarity_min',\n",
    " 'title_query_cosine_similarity_mean', 'title_query_cosine_similarity_std',\n",
    "    'title_prefix_leven', 'title_prefix_leven_rate',\n",
    " 'title_query_leven_sum', 'title_query_leven_max', 'title_query_leven_min',\n",
    " 'title_query_leven_mean', 'title_query_leven_std',\n",
    "    'prefix', 'query_prediction', 'title', 'tag',\n",
    "      ]\n",
    "\n",
    "train_fea = fea + ['index', 'label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导出特征工程文件\n",
    "def exportDf(df, fileName):\n",
    "    df.to_csv('../temp/%s.csv' % fileName, header=True, index=True)\n",
    "\n",
    "exportDf(train_df[train_fea], 'train_online_df')\n",
    "exportDf(test_df[fea], 'test_online_df')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
