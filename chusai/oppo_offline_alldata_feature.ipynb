{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "from collections import Counter\n",
    "import functools\n",
    "from gensim.models import word2vec\n",
    "import Levenshtein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_26 = pd.read_table('../data/oppo_round1_train_20180926.txt', names=['prefix', 'query_prediction', 'title', 'tag', 'label'], header=None, quoting=3)\n",
    "train_df_29 = pd.read_table('../data/oppo_round1_train_20180929.txt', names=['prefix', 'query_prediction', 'title', 'tag', 'label'], header=None, quoting=3)\n",
    "train_df = pd.concat([train_df_26, train_df_29])\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df['index'] = train_df.index\n",
    "valid_df_26 = pd.read_table('../data/oppo_round1_vali_20180926.txt', names=['prefix', 'query_prediction', 'title', 'tag', 'label'], header=None, quoting=3)\n",
    "valid_df_29 = pd.read_table('../data/oppo_round1_vali_20180929.txt', names=['prefix', 'query_prediction', 'title', 'tag', 'label'], header=None, quoting=3)\n",
    "valid_df = pd.concat([valid_df_26, valid_df_29])\n",
    "valid_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nan_to_string(df):\n",
    "    df['prefix'] = df['prefix'].astype(str)\n",
    "    df['title'] = df['title'].astype(str)\n",
    "    df['tag'] = df['tag'].astype(str)\n",
    "    return df\n",
    "\n",
    "train_df = nan_to_string(train_df)\n",
    "valid_df = nan_to_string(valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index prefix                                   query_prediction  \\\n",
      "0      0   湖北工业  {\"湖北工业大学教务处\": \"0.013\", \"湖北工业大学\": \"0.639\", \"湖北工...   \n",
      "1      1     实时  {\"实时票房_中国票房\": \"0.070\", \"实时天气预报\": \"0.008\", \"实时话...   \n",
      "2      2    一元二  {\"一元二次不等式的解法\": \"0.019\", \"一元二次方程计算题\": \"0.015\", ...   \n",
      "3      3     刺激  {\"刺激战场怎么改名字\": \"0.012\", \"刺激战场黑夜模式\": \"0.012\", \"刺...   \n",
      "4      4    长颈鹿  {\"长颈鹿英语\": \"0.067\", \"长颈鹿\": \"0.156\", \"长颈鹿英语怎么样\":...   \n",
      "\n",
      "         title tag  label                              query_prediction_dict  \\\n",
      "0       湖北工业大学  百科      1  {'湖北工业大学教务处': '0.013', '湖北工业大学': '0.639', '湖北工...   \n",
      "1  如何网上查看实时公交？  经验      0  {'实时票房_中国票房': '0.070', '实时天气预报': '0.008', '实时话...   \n",
      "2     一元二次方程解法  百科      1  {'一元二次不等式的解法': '0.019', '一元二次方程计算题': '0.015', ...   \n",
      "3       刺激战场官网  网站      0  {'刺激战场怎么改名字': '0.012', '刺激战场黑夜模式': '0.012', '刺...   \n",
      "4          长颈鹿  百科      1  {'长颈鹿英语': '0.067', '长颈鹿': '0.156', '长颈鹿英语怎么样':...   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [湖北工业大学教务处, 湖北工业大学, 湖北工业大学官网, 湖北工业大学宿舍, 湖北工业大学...   \n",
      "1  [实时票房_中国票房, 实时天气预报, 实时话费什么意思, 实时公交, 实时票房排行榜, 实...   \n",
      "2  [一元二次不等式的解法, 一元二次方程计算题, 一元二次不等式, 一元二次方程的解法, 一元...   \n",
      "3  [刺激战场怎么改名字, 刺激战场黑夜模式, 刺激牛牛, 刺激战场官网, 刺激战场体验服, 刺...   \n",
      "4  [长颈鹿英语, 长颈鹿, 长颈鹿英语怎么样, 长颈鹿英文, 长颈鹿卡通图片, 长颈鹿英语怎么...   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.013, 0.639, 0.084, 0.005, 0.005, 0.005, 0.0...                       11   \n",
      "1  [0.07, 0.008, 0.011, 0.056, 0.312, 0.013, 0.01...                       11   \n",
      "2  [0.019, 0.015, 0.038, 0.073, 0.0, 0.019, 0.072...                       11   \n",
      "3  [0.012, 0.012, 0.011, 0.01, 0.016, 0.02, 0.047...                       11   \n",
      "4  [0.067, 0.156, 0.011, 0.018, 0.011, 0.019, 0.0...                       11   \n",
      "\n",
      "   query_prediction_max  query_prediction_min  query_prediction_mean  \\\n",
      "0                 0.639                 0.004               0.079455   \n",
      "1                 0.312                 0.002               0.071182   \n",
      "2                 0.290                 0.000               0.064545   \n",
      "3                 0.106                 0.010               0.025364   \n",
      "4                 0.180                 0.009               0.053818   \n",
      "\n",
      "   query_prediction_std  \n",
      "0              0.178811  \n",
      "1              0.095993  \n",
      "2              0.077841  \n",
      "3              0.027480  \n",
      "4              0.058398  \n"
     ]
    }
   ],
   "source": [
    "def get_float_list(x):\n",
    "    return_list = []\n",
    "    for temp in x:\n",
    "        return_list.append(float(temp))\n",
    "    return return_list\n",
    "\n",
    "# 处理跟query_prediction相关的统计特征\n",
    "def get_query_prediction_feature(df):\n",
    "    df['query_prediction_dict'] = df['query_prediction'].map(lambda x : dict() if x is np.nan else eval(x))\n",
    "    df['query_prediction_keys'] = df['query_prediction_dict'].map(lambda x : list(x.keys()))\n",
    "    df['query_prediction_values'] = df['query_prediction_dict'].map(lambda x : get_float_list(list(x.values())))\n",
    "    df['query_prediction_number'] = df['query_prediction_keys'].map(lambda x : len(x))\n",
    "    df['query_prediction_max'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.max(x))\n",
    "    df['query_prediction_min'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.min(x))\n",
    "    df['query_prediction_mean'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.mean(x))\n",
    "    df['query_prediction_std'] = df['query_prediction_values'].map(lambda x : np.nan if len(x) == 0 else np.std(x))\n",
    "    return df\n",
    "\n",
    "train_df = get_query_prediction_feature(train_df)\n",
    "valid_df = get_query_prediction_feature(valid_df)\n",
    "print(valid_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix : finish!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : finish!!!\n",
      "tag : finish!!!\n",
      "query_prediction : finish!!!\n",
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "0      1  !是什么意思                                                NaN   \n",
      "0      2  !是什么意思                                                NaN   \n",
      "1      3  !是什么意思                                                NaN   \n",
      "1      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "0  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "0  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "1   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "1   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "0                                                 {}   \n",
      "0                                                 {}   \n",
      "1                                                 {}   \n",
      "1                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "0                                                 []   \n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "1                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "0                                                 []                        0   \n",
      "0                                                 []                        0   \n",
      "1                                                 []                        0   \n",
      "1                                                 []                        0   \n",
      "\n",
      "               ...                prefix_click_number  title_count  \\\n",
      "0              ...                               25.0         24.0   \n",
      "0              ...                                6.0          6.0   \n",
      "0              ...                                8.0          7.0   \n",
      "1              ...                                8.0          6.0   \n",
      "1              ...                                6.0          6.0   \n",
      "\n",
      "   title_rate  title_click_number  tag_count  tag_rate  tag_click_number  \\\n",
      "0    0.992779                24.0     205676  0.246259             50649   \n",
      "0    0.653603                 4.0     211811  0.298276             63178   \n",
      "0    0.563876                 4.0     211637  0.297278             62915   \n",
      "1    0.653676                 4.0     205676  0.246259             50649   \n",
      "1    0.335249                 2.0     205611  0.245821             50543   \n",
      "\n",
      "   query_prediction_count  query_prediction_rate  \\\n",
      "0                    26.0               0.458966   \n",
      "0                     NaN                    NaN   \n",
      "0                     NaN                    NaN   \n",
      "1                     NaN                    NaN   \n",
      "1                     NaN                    NaN   \n",
      "\n",
      "   query_prediction_click_number  \n",
      "0                           12.0  \n",
      "0                            NaN  \n",
      "0                            NaN  \n",
      "1                            NaN  \n",
      "1                            NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def getBayesSmoothParam(origion_rate):\n",
    "    origion_rate_mean = origion_rate.mean()\n",
    "    origion_rate_var = origion_rate.var()\n",
    "    alpha = origion_rate_mean / origion_rate_var * (origion_rate_mean * (1 - origion_rate_mean) - origion_rate_var)\n",
    "    beta = (1 - origion_rate_mean) / origion_rate_var * (origion_rate_mean * (1 - origion_rate_mean) - origion_rate_var)\n",
    "#     print('origion_rate_mean : ', origion_rate_mean)\n",
    "#     print('origion_rate_var : ', origion_rate_var)\n",
    "#     print('alpha : ', alpha)\n",
    "#     print('beta : ', beta)\n",
    "    return alpha, beta\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2018, shuffle=True)\n",
    "\n",
    "# 统计单维度的转化率特征\n",
    "def get_single_dimension_rate_feature(train_df, valid_df, fea_set):\n",
    "    for fea in fea_set:\n",
    "        train_temp_df = pd.DataFrame()\n",
    "        for index, (train_index, test_index) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "            temp_df = train_df[[fea, 'label']].iloc[train_index].copy()\n",
    "            temp_pivot_table = pd.pivot_table(temp_df, index=fea, values='label', aggfunc={len, np.mean, np.sum})\n",
    "            temp_pivot_table.reset_index(inplace=True)\n",
    "            temp_pivot_table.rename(columns={'len':fea + '_count', 'mean':fea + '_rate', 'sum':fea + '_click_number'}, inplace=True)\n",
    "            alpha, beta = getBayesSmoothParam(temp_pivot_table[fea + '_rate'])\n",
    "            temp_pivot_table[fea + '_rate'] = (temp_pivot_table[fea + '_click_number'] + alpha) / (temp_pivot_table[fea + '_count'] + alpha + beta)\n",
    "#             del temp_pivot_table[fea + '_click_number']\n",
    "            fea_df = train_df.iloc[test_index].copy()\n",
    "            fea_df = pd.merge(fea_df, temp_pivot_table, on=fea, how='left')\n",
    "#             print(fea_df.head())\n",
    "            train_temp_df = pd.concat([train_temp_df, fea_df])\n",
    "        temp_df = train_df[[fea, 'label']].copy()\n",
    "        temp_pivot_table = pd.pivot_table(temp_df, index=fea, values='label', aggfunc={len, np.mean, np.sum})\n",
    "        temp_pivot_table.reset_index(inplace=True)\n",
    "        temp_pivot_table.rename(columns={'len':fea + '_count', 'mean':fea + '_rate', 'sum':fea + '_click_number'}, inplace=True)\n",
    "        alpha, beta = getBayesSmoothParam(temp_pivot_table[fea + '_rate'])\n",
    "        temp_pivot_table[fea + '_rate'] = (temp_pivot_table[fea + '_click_number'] + alpha) / (temp_pivot_table[fea + '_count'] + alpha + beta)\n",
    "#             del temp_pivot_table[fea + '_click_number']\n",
    "        valid_df = pd.merge(valid_df, temp_pivot_table, on=fea, how='left')\n",
    "        print(fea + ' : finish!!!')\n",
    "        train_df = train_temp_df\n",
    "        train_df.sort_index(by='index', ascending=True, inplace=True)\n",
    "    return train_df, valid_df\n",
    "    \n",
    "fea_set = ['prefix', 'title', 'tag', 'query_prediction']\n",
    "train_df, valid_df = get_single_dimension_rate_feature(train_df, valid_df, fea_set)\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix_title : finish!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix_tag : finish!!!\n",
      "title_tag : finish!!!\n",
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "0      1  !是什么意思                                                NaN   \n",
      "0      2  !是什么意思                                                NaN   \n",
      "1      3  !是什么意思                                                NaN   \n",
      "1      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "0  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "0  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "1   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "1   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "0                                                 {}   \n",
      "0                                                 {}   \n",
      "1                                                 {}   \n",
      "1                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "0                                                 []   \n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "1                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "0                                                 []                        0   \n",
      "0                                                 []                        0   \n",
      "1                                                 []                        0   \n",
      "1                                                 []                        0   \n",
      "\n",
      "            ...            query_prediction_click_number  prefix_title_count  \\\n",
      "0           ...                                     12.0                24.0   \n",
      "0           ...                                      NaN                 6.0   \n",
      "0           ...                                      NaN                 7.0   \n",
      "1           ...                                      NaN                 6.0   \n",
      "1           ...                                      NaN                 6.0   \n",
      "\n",
      "   prefix_title_rate  prefix_title_click_number  prefix_tag_count  \\\n",
      "0           0.993690                       24.0              24.0   \n",
      "0           0.655158                        4.0               6.0   \n",
      "0           0.564784                        4.0               7.0   \n",
      "1           0.655258                        4.0               6.0   \n",
      "1           0.334993                        2.0               6.0   \n",
      "\n",
      "   prefix_tag_rate  prefix_tag_click_number  title_tag_count  title_tag_rate  \\\n",
      "0         0.987836                     24.0             24.0        0.993772   \n",
      "0         0.645398                      4.0              6.0        0.655380   \n",
      "0         0.559253                      4.0              7.0        0.564914   \n",
      "1         0.645567                      4.0              6.0        0.655446   \n",
      "1         0.337036                      2.0              6.0        0.335063   \n",
      "\n",
      "   title_tag_click_number  \n",
      "0                    24.0  \n",
      "0                     4.0  \n",
      "0                     4.0  \n",
      "1                     4.0  \n",
      "1                     2.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计双维度交叉转化率\n",
    "def get_jiaocha_dimension_rate_feature(train_df, valid_df, fea_set):\n",
    "    for i in range(len(fea_set)):\n",
    "        for j in range((i+1), len(fea_set)):\n",
    "            fea1 = fea_set[i]\n",
    "            fea2 = fea_set[j]\n",
    "            train_temp_df = pd.DataFrame()\n",
    "            for index, (train_index, test_index) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "                temp_df = train_df[[fea1, fea2, 'label']].iloc[train_index].copy()\n",
    "                temp_pivot_table = pd.pivot_table(temp_df, index=[fea1, fea2], values='label', aggfunc={len, np.mean, np.sum})\n",
    "                temp_pivot_table.reset_index(inplace=True)\n",
    "                temp_pivot_table.rename(columns={'len':fea1 + '_' + fea2 + '_count', 'mean':fea1 + '_' + fea2 + '_rate', 'sum':fea1 + '_' + fea2 + '_click_number'}, inplace=True)\n",
    "                alpha, beta = getBayesSmoothParam(temp_pivot_table[fea1 + '_' + fea2 + '_rate'])\n",
    "                temp_pivot_table[fea1 + '_' + fea2 + '_rate'] = (temp_pivot_table[fea1 + '_' + fea2 + '_click_number'] + alpha) / (temp_pivot_table[fea1 + '_' + fea2 + '_count'] + alpha + beta)\n",
    "#                 del temp_pivot_table[fea1 + '_' + fea2 + '_click_number']\n",
    "                fea_df = train_df.iloc[test_index].copy()\n",
    "                fea_df = pd.merge(fea_df, temp_pivot_table, on=[fea1, fea2], how='left')\n",
    "                train_temp_df = pd.concat([train_temp_df, fea_df])\n",
    "            temp_df = train_df[[fea1, fea2, 'label']].copy()\n",
    "            temp_pivot_table = pd.pivot_table(temp_df, index=[fea1, fea2], values='label', aggfunc={len, np.mean, np.sum})\n",
    "            temp_pivot_table.reset_index(inplace=True)\n",
    "            temp_pivot_table.rename(columns={'len':fea1 + '_' + fea2 + '_count', 'mean':fea1 + '_' + fea2 + '_rate', 'sum':fea1 + '_' + fea2 + '_click_number'}, inplace=True)\n",
    "            alpha, beta = getBayesSmoothParam(temp_pivot_table[fea1 + '_' + fea2 + '_rate'])\n",
    "            temp_pivot_table[fea1 + '_' + fea2 + '_rate'] = (temp_pivot_table[fea1 + '_' + fea2 + '_click_number'] + alpha) / (temp_pivot_table[fea1 + '_' + fea2 + '_count'] + alpha + beta)\n",
    "#             del temp_pivot_table[fea1 + '_' + fea2 + '_click_number']\n",
    "            print(fea1 + '_' + fea2 + ' : finish!!!')\n",
    "            valid_df = pd.merge(valid_df, temp_pivot_table, on=[fea1, fea2], how='left')\n",
    "            train_df = train_temp_df\n",
    "            train_df.sort_index(by='index', ascending=True, inplace=True)\n",
    "    return train_df, valid_df\n",
    "\n",
    "jiaocha_fea_set = ['prefix', 'title', 'tag']\n",
    "train_df, valid_df = get_jiaocha_dimension_rate_feature(train_df, valid_df, jiaocha_fea_set)\n",
    "print(train_df.head())\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计一些是否交叉的特征\n",
    "def get_is_title_in_query_feature(df):\n",
    "    x = df['title']\n",
    "    y = df['query_prediction_keys']\n",
    "    is_title_in_query = np.nan\n",
    "    if len(y) > 0:\n",
    "        if str(x) in str(y):\n",
    "            is_title_in_query = 1\n",
    "        else:\n",
    "            is_title_in_query = 0\n",
    "    return is_title_in_query\n",
    "\n",
    "def get_is_prefix_in_title_feature(df):\n",
    "    x = df['prefix']\n",
    "    y = df['title']\n",
    "    is_prefix_in_title = np.nan\n",
    "    if str(x) in str(y):\n",
    "        is_prefix_in_title = 1\n",
    "    else:\n",
    "        is_prefix_in_title = 0\n",
    "    return is_prefix_in_title\n",
    "\n",
    "train_df['is_title_in_query'] = train_df[['title', 'query_prediction_keys']].apply(get_is_title_in_query_feature, axis = 1)\n",
    "valid_df['is_title_in_query'] = valid_df[['title', 'query_prediction_keys']].apply(get_is_title_in_query_feature, axis = 1)\n",
    "\n",
    "train_df['is_prefix_in_title'] = train_df[['prefix', 'title']].apply(get_is_prefix_in_title_feature, axis = 1)\n",
    "valid_df['is_prefix_in_title'] = valid_df[['prefix', 'title']].apply(get_is_prefix_in_title_feature, axis = 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "1      1  !是什么意思                                                NaN   \n",
      "2      2  !是什么意思                                                NaN   \n",
      "3      3  !是什么意思                                                NaN   \n",
      "4      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "1  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "2  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "3   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "4   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "1                                                 {}   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "1                                                 []                        0   \n",
      "2                                                 []                        0   \n",
      "3                                                 []                        0   \n",
      "4                                                 []                        0   \n",
      "\n",
      "               ...               is_title_in_query  is_prefix_in_title  \\\n",
      "0              ...                             0.0                   1   \n",
      "1              ...                             NaN                   1   \n",
      "2              ...                             NaN                   1   \n",
      "3              ...                             NaN                   1   \n",
      "4              ...                             NaN                   1   \n",
      "\n",
      "   title_tag_types  prefix_tag_types  tag_title_types  tag_prefix_types  \\\n",
      "0                1                 4            24641             30257   \n",
      "1                1                 2            58790             47451   \n",
      "2                1                 2            58790             47451   \n",
      "3                1                 2            24641             30257   \n",
      "4                1                 2            24641             30257   \n",
      "\n",
      "   title_prefix_types  prefix_title_types  tag_query_prediction_types  \\\n",
      "0                   1                   4                       46910   \n",
      "1                   1                   2                       73254   \n",
      "2                   1                   2                       73254   \n",
      "3                   1                   2                       46910   \n",
      "4                   1                   2                       46910   \n",
      "\n",
      "   title_query_prediction_types  \n",
      "0                           2.0  \n",
      "1                           NaN  \n",
      "2                           NaN  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计一些交叉种类特征\n",
    "def get_jiaocha_type_feature(train_df, valid_df, jiaocha_type_list):\n",
    "    for jiaocha_type in jiaocha_type_list:\n",
    "        fea1 = jiaocha_type[0]\n",
    "        fea2 = jiaocha_type[1]\n",
    "        temp_df = pd.concat([train_df, valid_df])\n",
    "        temp_pivot_table = pd.pivot_table(temp_df[[fea1, fea2, 'label']], index=[fea1, fea2], values='label', aggfunc=len)\n",
    "        temp_pivot_table.reset_index(inplace=True)\n",
    "        final_pivot_table = pd.pivot_table(temp_pivot_table, index=fea1, values=fea2, aggfunc=len)\n",
    "        final_pivot_table.reset_index(inplace=True)\n",
    "        final_pivot_table.rename(columns={fea2 : fea1 + '_' + fea2 + '_types'}, inplace=True)\n",
    "        train_df = pd.merge(train_df, final_pivot_table[[fea1, fea1 + '_' + fea2 + '_types']], on=fea1, how='left')\n",
    "        valid_df = pd.merge(valid_df, final_pivot_table[[fea1, fea1 + '_' + fea2 + '_types']], on=fea1, how='left')\n",
    "    return train_df, valid_df\n",
    "\n",
    "jiaocha_type_list = [['title', 'tag'], ['prefix', 'tag'], ['tag', 'title'], ['tag', 'prefix'], \n",
    "                     ['title', 'prefix'], ['prefix', 'title'], ['tag', 'query_prediction'], ['title', 'query_prediction']]\n",
    "train_df, valid_df = get_jiaocha_type_feature(train_df, valid_df, jiaocha_type_list)\n",
    "print(train_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "1      1  !是什么意思                                                NaN   \n",
      "2      2  !是什么意思                                                NaN   \n",
      "3      3  !是什么意思                                                NaN   \n",
      "4      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "1  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "2  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "3   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "4   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "1                                                 {}   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "1                                                 []                        0   \n",
      "2                                                 []                        0   \n",
      "3                                                 []                        0   \n",
      "4                                                 []                        0   \n",
      "\n",
      "        ...        prefix_len  title_len  query_prediction_key_len_max  \\\n",
      "0       ...                 2         11                          13.0   \n",
      "1       ...                 6         24                           NaN   \n",
      "2       ...                 6         24                           NaN   \n",
      "3       ...                 6         23                           NaN   \n",
      "4       ...                 6         23                           NaN   \n",
      "\n",
      "   query_prediction_key_len_min  query_prediction_key_len_mean  \\\n",
      "0                           2.0                       6.454545   \n",
      "1                           NaN                            NaN   \n",
      "2                           NaN                            NaN   \n",
      "3                           NaN                            NaN   \n",
      "4                           NaN                            NaN   \n",
      "\n",
      "   query_prediction_key_len_std  len_title-prefix  len_prefix/title  \\\n",
      "0                      2.675262                 9          0.181818   \n",
      "1                           NaN                18          0.250000   \n",
      "2                           NaN                18          0.250000   \n",
      "3                           NaN                17          0.260870   \n",
      "4                           NaN                17          0.260870   \n",
      "\n",
      "   len_mean-title  len_mean/title  \n",
      "0       -4.545455        0.586777  \n",
      "1             NaN             NaN  \n",
      "2             NaN             NaN  \n",
      "3             NaN             NaN  \n",
      "4             NaN             NaN  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_key_len_list(x):\n",
    "    return_list = []\n",
    "    for temp in x:\n",
    "        return_list.append(len(temp))\n",
    "    return return_list\n",
    "\n",
    "# 统计一些跟字符串长度相关的特征\n",
    "def get_string_len_feature(df):\n",
    "    df['prefix_len'] = df['prefix'].map(lambda x : np.nan if x is np.nan else len(x))\n",
    "    df['title_len'] = df['title'].map(lambda x : np.nan if x is np.nan else len(x))\n",
    "    df['query_prediction_key_len_list'] = df['query_prediction_keys'].map(lambda x : get_key_len_list(x))\n",
    "    df['query_prediction_key_len_max'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.max(x))\n",
    "    df['query_prediction_key_len_min'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.min(x))\n",
    "    df['query_prediction_key_len_mean'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.mean(x))\n",
    "    df['query_prediction_key_len_std'] = df['query_prediction_key_len_list'].map(lambda x : np.nan if len(x) == 0 else np.std(x))\n",
    "    df['len_title-prefix'] = df['title_len'] - df['prefix_len']\n",
    "    df['len_prefix/title'] = df['prefix_len'] / df['title_len']\n",
    "    df['len_mean-title'] = df['query_prediction_key_len_mean'] - df['title_len']\n",
    "    df['len_mean/title'] = df['query_prediction_key_len_mean'] / df['title_len']\n",
    "    del df['query_prediction_key_len_list']\n",
    "    return df\n",
    "\n",
    "train_df = get_string_len_feature(train_df)\n",
    "valid_df = get_string_len_feature(valid_df)\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "1      1  !是什么意思                                                NaN   \n",
      "2      2  !是什么意思                                                NaN   \n",
      "3      3  !是什么意思                                                NaN   \n",
      "4      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "1  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "2  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "3   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "4   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "1                                                 {}   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "1                                                 []                        0   \n",
      "2                                                 []                        0   \n",
      "3                                                 []                        0   \n",
      "4                                                 []                        0   \n",
      "\n",
      "            ...             query_prediction_key_len_max  \\\n",
      "0           ...                                     13.0   \n",
      "1           ...                                      NaN   \n",
      "2           ...                                      NaN   \n",
      "3           ...                                      NaN   \n",
      "4           ...                                      NaN   \n",
      "\n",
      "   query_prediction_key_len_min  query_prediction_key_len_mean  \\\n",
      "0                           2.0                       6.454545   \n",
      "1                           NaN                            NaN   \n",
      "2                           NaN                            NaN   \n",
      "3                           NaN                            NaN   \n",
      "4                           NaN                            NaN   \n",
      "\n",
      "   query_prediction_key_len_std  len_title-prefix  len_prefix/title  \\\n",
      "0                      2.675262                 9          0.181818   \n",
      "1                           NaN                18          0.250000   \n",
      "2                           NaN                18          0.250000   \n",
      "3                           NaN                17          0.260870   \n",
      "4                           NaN                17          0.260870   \n",
      "\n",
      "   len_mean-title  len_mean/title  title_prefix_leven  title_prefix_leven_rate  \n",
      "0       -4.545455        0.586777                   9                 0.642857  \n",
      "1             NaN             NaN                  18                 0.666667  \n",
      "2             NaN             NaN                  18                 0.666667  \n",
      "3             NaN             NaN                  17                 0.653846  \n",
      "4             NaN             NaN                  17                 0.653846  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计title跟prefix的编辑距离\n",
    "def get_title_prefix_levenshtein_distance(df):\n",
    "    title = str(df['title'])\n",
    "    prefix = str(df['prefix'])\n",
    "    return Levenshtein.distance(title, prefix)\n",
    "\n",
    "def get_title_prefix_levenshtein_distance_rate(df):\n",
    "    title_prefix_leven = df['title_prefix_leven']\n",
    "    title = df['title']\n",
    "    return (title_prefix_leven / (len(title) + 3))\n",
    "\n",
    "train_df['title_prefix_leven'] = train_df[['title', 'prefix']].apply(get_title_prefix_levenshtein_distance, axis=1)\n",
    "valid_df['title_prefix_leven'] = valid_df[['title', 'prefix']].apply(get_title_prefix_levenshtein_distance, axis=1)\n",
    "\n",
    "train_df['title_prefix_leven_rate'] = train_df[['title', 'title_prefix_leven']].apply(get_title_prefix_levenshtein_distance_rate, axis=1)\n",
    "valid_df['title_prefix_leven_rate'] = valid_df[['title', 'title_prefix_leven']].apply(get_title_prefix_levenshtein_distance_rate, axis=1)\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "1      1  !是什么意思                                                NaN   \n",
      "2      2  !是什么意思                                                NaN   \n",
      "3      3  !是什么意思                                                NaN   \n",
      "4      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "1  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "2  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "3   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "4   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "1                                                 {}   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "1                                                 []                        0   \n",
      "2                                                 []                        0   \n",
      "3                                                 []                        0   \n",
      "4                                                 []                        0   \n",
      "\n",
      "           ...            len_mean-title  len_mean/title  title_prefix_leven  \\\n",
      "0          ...                 -4.545455        0.586777                   9   \n",
      "1          ...                       NaN             NaN                  18   \n",
      "2          ...                       NaN             NaN                  18   \n",
      "3          ...                       NaN             NaN                  17   \n",
      "4          ...                       NaN             NaN                  17   \n",
      "\n",
      "   title_prefix_leven_rate                             title_query_leven_list  \\\n",
      "0                 0.642857  [0.08, 0.36, 0.07200000000000001, 0.351, 0.420...   \n",
      "1                 0.666667                                                 []   \n",
      "2                 0.666667                                                 []   \n",
      "3                 0.653846                                                 []   \n",
      "4                 0.653846                                                 []   \n",
      "\n",
      "   title_query_leven_sum  title_query_leven_max  title_query_leven_min  \\\n",
      "0                  7.944                  5.832                  0.064   \n",
      "1                    NaN                    NaN                    NaN   \n",
      "2                    NaN                    NaN                    NaN   \n",
      "3                    NaN                    NaN                    NaN   \n",
      "4                    NaN                    NaN                    NaN   \n",
      "\n",
      "   title_query_leven_mean  title_query_leven_std  \n",
      "0                0.722182               1.623287  \n",
      "1                     NaN                    NaN  \n",
      "2                     NaN                    NaN  \n",
      "3                     NaN                    NaN  \n",
      "4                     NaN                    NaN  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# 统计title跟query_prediction编辑距离相关的特征\n",
    "def get_title_query_levenshtein_distance_list(df):\n",
    "    query_keys_list = df['query_prediction_keys']\n",
    "    query_values_list = df['query_prediction_values']\n",
    "    title = df['title']\n",
    "    return_list = list()\n",
    "    for i in range(len(query_keys_list)):\n",
    "        distance = Levenshtein.distance(title, query_keys_list[i])\n",
    "        return_list.append(distance * query_values_list[i])\n",
    "    return return_list\n",
    "\n",
    "def get_title_query_levenshtein_distance_feature(df):\n",
    "    df['title_query_leven_list'] = df[['query_prediction_keys', 'query_prediction_values', 'title']].apply(get_title_query_levenshtein_distance_list, axis=1)\n",
    "    df['title_query_leven_sum'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.sum(x))\n",
    "    df['title_query_leven_max'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.max(x))\n",
    "    df['title_query_leven_min'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.min(x))\n",
    "    df['title_query_leven_mean'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.mean(x))\n",
    "    df['title_query_leven_std'] = df['title_query_leven_list'].map(lambda x : np.nan if len(x) == 0 else np.std(x))\n",
    "    return df\n",
    "\n",
    "train_df = get_title_query_levenshtein_distance_feature(train_df)\n",
    "valid_df = get_title_query_levenshtein_distance_feature(valid_df)\n",
    "print(train_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/jieba/__init__.py\", line 152, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmpeku7tcj9' -> '/tmp/jieba.cache'\n",
      "Loading model cost 1.450 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "1      1  !是什么意思                                                NaN   \n",
      "2      2  !是什么意思                                                NaN   \n",
      "3      3  !是什么意思                                                NaN   \n",
      "4      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "1  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "2  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "3   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "4   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "1                                                 {}   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "1                                                 []                        0   \n",
      "2                                                 []                        0   \n",
      "3                                                 []                        0   \n",
      "4                                                 []                        0   \n",
      "\n",
      "          ...          title_query_leven_sum  title_query_leven_max  \\\n",
      "0         ...                          7.944                  5.832   \n",
      "1         ...                            NaN                    NaN   \n",
      "2         ...                            NaN                    NaN   \n",
      "3         ...                            NaN                    NaN   \n",
      "4         ...                            NaN                    NaN   \n",
      "\n",
      "   title_query_leven_min  title_query_leven_mean  title_query_leven_std  \\\n",
      "0                  0.064                0.722182               1.623287   \n",
      "1                    NaN                     NaN                    NaN   \n",
      "2                    NaN                     NaN                    NaN   \n",
      "3                    NaN                     NaN                    NaN   \n",
      "4                    NaN                     NaN                    NaN   \n",
      "\n",
      "                      query_prediction_key_sentences  \\\n",
      "0  逆行我的1997逆行性遗忘逆行遗忘症逆行性遗忘症逆行扣几分逆行我的1997 白色米饭逆行诸天...   \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4                                                      \n",
      "\n",
      "                    query_prediction_key_jieba_words  \\\n",
      "0  [逆行, 我, 的, 1997, 逆行, 性, 遗忘, 逆行, 遗忘症, 逆行, 性, 遗忘...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                              query_prediction_words  \\\n",
      "0  [[逆行, 我, 的, 1997], [逆行, 性, 遗忘], [逆行, 遗忘症], [逆行...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                   title_jieba_words  prefix_jieba_words  \n",
      "0                          [右, 拐拐, 到, 逆, 行车道, 扣, 几分]                [逆行]  \n",
      "1  [做, 完, 胆管, 支架, 的, 手术, 白血球, 高, !, 还, 不, 发烧, !, ...      [!, 是, 什么, 意思]  \n",
      "2  [做, 完, 胆管, 支架, 的, 手术, 白血球, 高, !, 还, 不, 发烧, !, ...      [!, 是, 什么, 意思]  \n",
      "3  [山有, 顶, %, 2C, 海有, 边, %, 2C, 此情, 无止境, !, 是, 什么...      [!, 是, 什么, 意思]  \n",
      "4  [山有, 顶, %, 2C, 海有, 边, %, 2C, 此情, 无止境, !, 是, 什么...      [!, 是, 什么, 意思]  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "#分词方法，调用结巴接口\n",
    "def jieba_seg_to_list(sentence, pos=False):\n",
    "    if not pos:\n",
    "        #不进行词性标注的分词方法\n",
    "        seg_list = jieba.cut(sentence)\n",
    "    else:\n",
    "        #进行词性标注的分词方法\n",
    "        seg_list = psg.cut(sentence)\n",
    "    return seg_list\n",
    "\n",
    "#去除干扰词\n",
    "def jieba_word_filter(seg_list, pos=False):\n",
    "    \n",
    "    filter_list = []\n",
    "    #根据pos参数选择是否词性过滤\n",
    "    #不进行词性过滤，则将词性都标记为n，表示全部保留\n",
    "    for seg in seg_list:\n",
    "        if not pos:\n",
    "            word = seg\n",
    "            flag = 'n'\n",
    "        else:\n",
    "            word = seg.word\n",
    "            flag = seg.flag\n",
    "        if not flag.startswith('n'):\n",
    "            continue\n",
    "        filter_list.append(word)\n",
    "    return filter_list\n",
    "\n",
    "def jieba_word_deal(sentence, pos=False):\n",
    "    #调用上面方式对数据集进行处理，处理后的每条数据仅保留非干扰词\n",
    "    seg_list = jieba_seg_to_list(sentence, pos)\n",
    "    filter_list = jieba_word_filter(seg_list, pos)\n",
    "    return filter_list\n",
    "\n",
    "def get_prefix_prediction_key_sentences(x):\n",
    "    prefix_prediction_key_sentences = \"\"\n",
    "    for temp in x:\n",
    "        if len(prefix_prediction_key_sentences) > 0:\n",
    "            prefix_prediction_key_sentences = prefix_prediction_key_sentences + temp\n",
    "        else:\n",
    "            prefix_prediction_key_sentences = temp\n",
    "    return prefix_prediction_key_sentences\n",
    "\n",
    "def get_max_query_key_sentences(x):\n",
    "    if len(x) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return max(x, key=x.get)\n",
    "\n",
    "def get_jieba_word(df):\n",
    "    df['query_prediction_key_sentences'] = df['query_prediction_keys'].map(lambda x : get_prefix_prediction_key_sentences(x))\n",
    "#     df['query_prediction_key_sentences'] = df['query_prediction_dict'].map(lambda x : get_max_query_key_sentences(x))\n",
    "    df['query_prediction_key_jieba_words'] = df['query_prediction_key_sentences'].map(lambda x : jieba_word_deal(x, False))\n",
    "    df['query_prediction_words'] = df['query_prediction_keys'].map(lambda x : [jieba_word_deal(j, False) for j in x] if len(x) > 0 else np.nan)\n",
    "    df['title_jieba_words'] = df['title'].map(lambda x : jieba_word_deal(x, False))\n",
    "    df['prefix_jieba_words'] = df['prefix'].map(lambda x : jieba_word_deal(x, False))\n",
    "#     del df['query_prediction_key_sentences']\n",
    "    return df\n",
    "\n",
    "train_df = get_jieba_word(train_df)\n",
    "valid_df = get_jieba_word(valid_df)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_t_word_match finish!!!\n",
      "q_t_jaccard finish!!!\n",
      "q_t_common_words finish!!!\n",
      "q_t_total_unique_words finish!!!\n",
      "q_t_wc_diff finish!!!\n",
      "q_t_wc_ratio finish!!!\n",
      "q_t_wc_diff_unique finish!!!\n",
      "q_t_wc_ratio_unique finish!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab-zhao.yinhu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_t_tfidf_word_match_share finish!!!\n",
      "p_t_word_match finish!!!\n",
      "p_t_jaccard finish!!!\n",
      "p_t_common_words finish!!!\n",
      "p_t_total_unique_words finish!!!\n",
      "p_t_wc_diff finish!!!\n",
      "p_t_wc_ratio finish!!!\n",
      "p_t_wc_diff_unique finish!!!\n",
      "p_t_wc_ratio_unique finish!!!\n",
      "p_t_tfidf_word_match_share finish!!!\n",
      "p_q_word_match finish!!!\n",
      "p_q_jaccard finish!!!\n",
      "p_q_common_words finish!!!\n",
      "p_q_total_unique_words finish!!!\n",
      "p_q_wc_diff finish!!!\n",
      "p_q_wc_ratio finish!!!\n",
      "p_q_wc_diff_unique finish!!!\n",
      "p_q_wc_ratio_unique finish!!!\n",
      "p_q_tfidf_word_match_share finish!!!\n",
      "   index  prefix                                   query_prediction  \\\n",
      "0      0      逆行  {\"逆行我的1997\": \"0.008\", \"逆行性遗忘\": \"0.040\", \"逆行遗忘症...   \n",
      "1      1  !是什么意思                                                NaN   \n",
      "2      2  !是什么意思                                                NaN   \n",
      "3      3  !是什么意思                                                NaN   \n",
      "4      4  !是什么意思                                                NaN   \n",
      "\n",
      "                      title tag  label  \\\n",
      "0               右拐拐到逆行车道扣几分  知道      1   \n",
      "1  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "2  做完胆管支架的手术白血球高!还不发烧!是什么意思  健康      1   \n",
      "3   山有顶%2C海有边%2C此情无止境!是什么意思  知道      0   \n",
      "4   山有顶%2C海有边%2C此情无止境!是什么意思  知道      1   \n",
      "\n",
      "                               query_prediction_dict  \\\n",
      "0  {'逆行我的1997': '0.008', '逆行性遗忘': '0.040', '逆行遗忘症...   \n",
      "1                                                 {}   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                               query_prediction_keys  \\\n",
      "0  [逆行我的1997, 逆行性遗忘, 逆行遗忘症, 逆行性遗忘症, 逆行扣几分, 逆行我的19...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                             query_prediction_values  query_prediction_number  \\\n",
      "0  [0.008, 0.04, 0.008, 0.039, 0.07, 0.008, 0.648...                       11   \n",
      "1                                                 []                        0   \n",
      "2                                                 []                        0   \n",
      "3                                                 []                        0   \n",
      "4                                                 []                        0   \n",
      "\n",
      "              ...              p_t_tfidf_word_match_share  p_q_word_match  \\\n",
      "0             ...                                0.000000             0.1   \n",
      "1             ...                                0.223633             0.0   \n",
      "2             ...                                0.223633             0.0   \n",
      "3             ...                                0.174507             0.0   \n",
      "4             ...                                0.174507             0.0   \n",
      "\n",
      "   p_q_jaccard  p_q_common_words  p_q_total_unique_words  p_q_wc_diff  \\\n",
      "0     0.052632                 1                      19           38   \n",
      "1     0.000000                 0                       4            4   \n",
      "2     0.000000                 0                       4            4   \n",
      "3     0.000000                 0                       4            4   \n",
      "4     0.000000                 0                       4            4   \n",
      "\n",
      "   p_q_wc_ratio  p_q_wc_diff_unique  p_q_wc_ratio_unique  \\\n",
      "0          39.0                  18                 19.0   \n",
      "1           NaN                   4                  NaN   \n",
      "2           NaN                   4                  NaN   \n",
      "3           NaN                   4                  NaN   \n",
      "4           NaN                   4                  NaN   \n",
      "\n",
      "   p_q_tfidf_word_match_share  \n",
      "0                    0.168245  \n",
      "1                    0.000000  \n",
      "2                    0.000000  \n",
      "3                    0.000000  \n",
      "4                    0.000000  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "def word_match_share(df):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in df[0]:\n",
    "        q1words[word] = 1\n",
    "    for word in df[1]:\n",
    "        q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "def jaccard(df):\n",
    "    wic = set(df[0]).intersection(set(df[1]))\n",
    "    uw = set(df[0]).union(df[1])\n",
    "    if len(uw) == 0:\n",
    "        uw = [1]\n",
    "    return (len(wic) / len(uw))\n",
    "\n",
    "def common_words(df):\n",
    "    return len(set(df[0]).intersection(set(df[1])))\n",
    "\n",
    "def total_unique_words(df):\n",
    "    return len(set(df[0]).union(df[1]))\n",
    "\n",
    "def wc_diff(df):\n",
    "    return abs(len(df[0]) - len(df[1]))\n",
    "\n",
    "def wc_ratio(df):\n",
    "    l1 = len(df[0])*1.0 \n",
    "    l2 = len(df[1])\n",
    "    if l2 == 0:\n",
    "        return np.nan\n",
    "    if l1 / l2:\n",
    "        return l2 / l1\n",
    "    else:\n",
    "        return l1 / l2\n",
    "\n",
    "def wc_diff_unique(df):\n",
    "    return abs(len(set(df[0])) - len(set(df[1])))\n",
    "    \n",
    "def wc_ratio_unique(df):\n",
    "    l1 = len(set(df[0])) * 1.0\n",
    "    l2 = len(set(df[1]))\n",
    "    if l2 == 0:\n",
    "        return np.nan\n",
    "    if l1 / l2:\n",
    "        return l2 / l1\n",
    "    else:\n",
    "        return l1 / l2\n",
    "    \n",
    "def tfidf_word_match_share(df, weights=None):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in df[0]:\n",
    "        q1words[word] = 1\n",
    "    for word in df[1]:\n",
    "        q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R\n",
    "\n",
    "def deal_word_for_all(train_df, valid_df, fea1, fea2, func, colName):\n",
    "    train_df[colName] = train_df[[fea1, fea2]].apply(func, axis=1)\n",
    "    valid_df[colName] = valid_df[[fea1, fea2]].apply(func, axis=1)\n",
    "    print(colName + ' finish!!!')\n",
    "    return train_df, valid_df\n",
    "                   \n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "\n",
    "def get_word_statistic_feature(train_df, valid_df, col_list):\n",
    "    df = pd.concat([train_df[['query_prediction_key_jieba_words', 'title_jieba_words', 'prefix_jieba_words']], valid_df[['query_prediction_key_jieba_words', 'title_jieba_words', 'prefix_jieba_words']]])\n",
    "    train_qs = pd.Series(df['query_prediction_key_jieba_words'].tolist() + df['title_jieba_words'].tolist() + df['prefix_jieba_words'].tolist())\n",
    "    words = [x for y in train_qs for x in y]\n",
    "    counts = Counter(words)\n",
    "    weights = {word: get_weight(count) for word, count in counts.items()}\n",
    "    for col in col_list:\n",
    "        fea1 = col[0]\n",
    "        fea2 = col[1]\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, word_match_share, fea1[0] + '_' + fea2[0] + '_word_match')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, jaccard, fea1[0] + '_' + fea2[0] + '_jaccard')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, common_words, fea1[0] + '_' + fea2[0] + '_common_words')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, total_unique_words, fea1[0] + '_' + fea2[0] + '_total_unique_words')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_diff, fea1[0] + '_' + fea2[0] + '_wc_diff')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_ratio, fea1[0] + '_' + fea2[0] + '_wc_ratio')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_diff_unique, fea1[0] + '_' + fea2[0] + '_wc_diff_unique')\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, wc_ratio_unique, fea1[0] + '_' + fea2[0] + '_wc_ratio_unique')\n",
    "        f = functools.partial(tfidf_word_match_share, weights=weights)\n",
    "        train_df, valid_df = deal_word_for_all(train_df, valid_df, fea1, fea2, f, fea1[0] + '_' + fea2[0] + '_tfidf_word_match_share')\n",
    "    return train_df, valid_df\n",
    "\n",
    "col_list = [['query_prediction_key_jieba_words', 'title_jieba_words'], ['prefix_jieba_words', 'title_jieba_words'], ['prefix_jieba_words', 'query_prediction_key_jieba_words']]\n",
    "train_df, valid_df = get_word_statistic_feature(train_df, valid_df, col_list)\n",
    "print(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 500  # Word vector dimensionality                      \n",
    "min_word_count = 1  # Minimum word count                        \n",
    "num_workers = 20       # Number of threads to run in parallel\n",
    "context = 5          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "word2vec_df = pd.concat([train_df[['query_prediction_words', 'title_jieba_words', 'prefix_jieba_words', 'query_prediction_number']], valid_df[['query_prediction_words', 'title_jieba_words', 'prefix_jieba_words', 'query_prediction_number']]])\n",
    "word2vec_df.reset_index(inplace=True)\n",
    "word2vec_list = word2vec_df['title_jieba_words'].tolist() + word2vec_df['prefix_jieba_words'].tolist() + [y for x in word2vec_df['query_prediction_words'][word2vec_df.query_prediction_number > 0] for y in x]\n",
    "model = word2vec.Word2Vec(word2vec_list, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "word_wv = model.wv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_w2v_array(word_list, word_wv, num_features):\n",
    "    word_vectors = np.zeros((len(word_list), num_features))\n",
    "    for i in range(len(word_list)):\n",
    "        word_vectors[i][:] = word_wv[str(word_list[i])]\n",
    "    mean_array = np.mean(word_vectors, axis=0)\n",
    "    return mean_array\n",
    "\n",
    "train_df['title_jieba_array'] = train_df['title_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "valid_df['title_jieba_array'] = valid_df['title_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "\n",
    "train_df['prefix_jieba_array'] = train_df['prefix_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "valid_df['prefix_jieba_array'] = valid_df['prefix_jieba_words'].map(lambda x : get_w2v_array(x, word_wv, num_features))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot : finish!!!\n",
      "norm : finish!!!\n",
      "cosine : finish!!!\n"
     ]
    }
   ],
   "source": [
    "def get_title_prefix_similarity(df, f_similarity):\n",
    "    title_array = df['title_jieba_array']\n",
    "    prefix_array = df['prefix_jieba_array']\n",
    "    similarity = 0\n",
    "    if f_similarity == 'dot':\n",
    "        similarity = np.dot(title_array, prefix_array)\n",
    "    elif f_similarity == 'norm':\n",
    "        similarity = np.linalg.norm(title_array - prefix_array)\n",
    "    else:\n",
    "        similarity = np.dot(title_array,prefix_array) / (np.linalg.norm(title_array) * np.linalg.norm(prefix_array))\n",
    "    return similarity\n",
    "\n",
    "# def get_title_query_similarity(df, f_similarity, word_wv, num_features):\n",
    "#     title_array = df['title_jieba_array']\n",
    "#     query_prediction_words = df['query_prediction_words']\n",
    "#     query_prediction_keys = df['query_prediction_keys']\n",
    "#     query_prediction_dict = df['query_prediction_dict']\n",
    "#     if len(query_prediction_keys) <= 0:\n",
    "#         return np.nan\n",
    "#     similarity = 0\n",
    "#     if f_similarity == 'dot':\n",
    "#         i = 0\n",
    "#         for key in query_prediction_keys:\n",
    "#             key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "#             similarity = similarity + np.dot(title_array, key_array) * float(query_prediction_dict[key])\n",
    "#             i = i + 1\n",
    "#     elif f_similarity == 'norm':\n",
    "#         i = 0\n",
    "#         for key in query_prediction_keys:\n",
    "#             key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "#             similarity = similarity + np.linalg.norm(title_array - key_array) * float(query_prediction_dict[key])\n",
    "#             i = i + 1\n",
    "#     else:\n",
    "#         i = 0\n",
    "#         for key in query_prediction_keys:\n",
    "#             key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "#             similarity = similarity + (np.dot(title_array, key_array) / (np.linalg.norm(title_array) * np.linalg.norm(key_array))) * float(query_prediction_dict[key])\n",
    "#             i = i + 1\n",
    "#     return similarity\n",
    "\n",
    "def get_title_query_similarity_list(df, f_similarity, word_wv, num_features):\n",
    "    title_array = df['title_jieba_array']\n",
    "    query_prediction_words = df['query_prediction_words']\n",
    "    query_prediction_keys = df['query_prediction_keys']\n",
    "    query_prediction_dict = df['query_prediction_dict']\n",
    "    similarity_list = list()\n",
    "    if len(query_prediction_keys) <= 0:\n",
    "        return similarity_list\n",
    "    if f_similarity == 'dot':\n",
    "        i = 0\n",
    "        for key in query_prediction_keys:\n",
    "            key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "            similarity = np.dot(title_array, key_array) * float(query_prediction_dict[key])\n",
    "            similarity_list.append(similarity)\n",
    "            i = i + 1\n",
    "    elif f_similarity == 'norm':\n",
    "        i = 0\n",
    "        for key in query_prediction_keys:\n",
    "            key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "            similarity = np.linalg.norm(title_array - key_array) * float(query_prediction_dict[key])\n",
    "            similarity_list.append(similarity)\n",
    "            i = i + 1\n",
    "    else:\n",
    "        i = 0\n",
    "        for key in query_prediction_keys:\n",
    "            key_array = get_w2v_array(query_prediction_words[i], word_wv, num_features)\n",
    "            similarity = (np.dot(title_array, key_array) / (np.linalg.norm(title_array) * np.linalg.norm(key_array))) * float(query_prediction_dict[key])\n",
    "            similarity_list.append(similarity)\n",
    "            i = i + 1\n",
    "    return similarity_list\n",
    "\n",
    "def get_similarity_feature(train_df, valid_df):\n",
    "    f_list = ['dot', 'norm', 'cosine']\n",
    "    for fun in f_list:\n",
    "        f_prefix_similarity = functools.partial(get_title_prefix_similarity, f_similarity=fun)\n",
    "        train_df['title_prefix_' + fun + '_similarity'] = train_df[['title_jieba_array', 'prefix_jieba_array']].apply(f_prefix_similarity, axis=1)\n",
    "        valid_df['title_prefix_' + fun + '_similarity'] = valid_df[['title_jieba_array', 'prefix_jieba_array']].apply(f_prefix_similarity, axis=1)\n",
    "#         f_query_similarity = functools.partial(get_title_query_similarity, f_similarity=fun, word_wv=word_wv, num_features=num_features)\n",
    "#         train_df['title_query_' + fun + '_similarity'] = train_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity, axis=1)\n",
    "#         valid_df['title_query_' + fun + '_similarity'] = valid_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity, axis=1)\n",
    "        f_query_similarity_list = functools.partial(get_title_query_similarity_list, f_similarity=fun, word_wv=word_wv, num_features=num_features)\n",
    "        train_df['title_query_' + fun + '_similarity_list'] = train_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity_list, axis=1)\n",
    "        valid_df['title_query_' + fun + '_similarity_list'] = valid_df[['title_jieba_array', 'query_prediction_words', 'query_prediction_keys', 'query_prediction_dict']].apply(f_query_similarity_list, axis=1)\n",
    "        train_df['title_query_' + fun + '_similarity'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.sum(x))\n",
    "        train_df['title_query_' + fun + '_similarity_max'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.max(x))\n",
    "        train_df['title_query_' + fun + '_similarity_min'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.min(x))\n",
    "        train_df['title_query_' + fun + '_similarity_mean'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.mean(x))\n",
    "        train_df['title_query_' + fun + '_similarity_std'] = train_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.std(x))\n",
    "        valid_df['title_query_' + fun + '_similarity'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.sum(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_max'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.max(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_min'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.min(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_mean'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.mean(x))\n",
    "        valid_df['title_query_' + fun + '_similarity_std'] = valid_df['title_query_' + fun + '_similarity_list'].map(lambda x : np.nan if len(x)==0 else np.std(x))\n",
    "        print(fun + ' : finish!!!')\n",
    "    return train_df, valid_df\n",
    "\n",
    "train_df, valid_df = get_similarity_feature(train_df, valid_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea = [\n",
    "    'query_prediction_number', 'query_prediction_max', 'query_prediction_min', 'query_prediction_mean', 'query_prediction_std',\n",
    "       'prefix_count', 'prefix_rate',\n",
    " 'title_count', 'title_rate', 'tag_count', 'tag_rate',\n",
    " 'query_prediction_count', 'query_prediction_rate', 'prefix_title_count',\n",
    " 'prefix_title_rate',  'prefix_tag_count', 'prefix_tag_rate',\n",
    " 'title_tag_count', 'title_tag_rate',\n",
    "    'prefix_click_number', 'title_click_number', 'query_prediction_click_number', 'prefix_tag_click_number', \n",
    "    'prefix_title_click_number', 'title_tag_click_number',\n",
    "    'is_title_in_query', 'is_prefix_in_title', \n",
    "    'title_tag_types', 'prefix_tag_types', 'tag_title_types', 'tag_prefix_types',\n",
    " 'title_prefix_types', 'prefix_title_types', 'tag_query_prediction_types', 'title_query_prediction_types',\n",
    "      'prefix_len', 'title_len',\n",
    " 'query_prediction_key_len_max', 'query_prediction_key_len_min',\n",
    " 'query_prediction_key_len_mean', 'query_prediction_key_len_std',\n",
    " 'len_title-prefix', 'len_prefix/title', 'len_mean-title', 'len_mean/title',\n",
    "    'q_t_word_match', 'q_t_jaccard', 'q_t_common_words',\n",
    " 'q_t_total_unique_words', 'q_t_wc_diff', 'q_t_wc_ratio',\n",
    " 'q_t_wc_diff_unique', 'q_t_wc_ratio_unique', 'q_t_tfidf_word_match_share',\n",
    " 'p_t_word_match', 'p_t_jaccard', 'p_t_common_words',\n",
    " 'p_t_total_unique_words', 'p_t_wc_diff', 'p_t_wc_ratio',\n",
    " 'p_t_wc_diff_unique', 'p_t_wc_ratio_unique', 'p_t_tfidf_word_match_share',\n",
    " 'p_q_word_match', 'p_q_jaccard', 'p_q_common_words',\n",
    " 'p_q_total_unique_words', 'p_q_wc_diff', 'p_q_wc_ratio',\n",
    " 'p_q_wc_diff_unique', 'p_q_wc_ratio_unique', 'p_q_tfidf_word_match_share',\n",
    "    'title_prefix_dot_similarity',\n",
    " 'title_query_dot_similarity', 'title_prefix_norm_similarity',\n",
    " 'title_query_norm_similarity', 'title_prefix_cosine_similarity',\n",
    " 'title_query_cosine_similarity',\n",
    "    'title_query_dot_similarity_max', 'title_query_dot_similarity_min',\n",
    " 'title_query_dot_similarity_mean', 'title_query_dot_similarity_std',\n",
    "    'title_query_norm_similarity_min', 'title_query_norm_similarity_mean',\n",
    " 'title_query_norm_similarity_std', 'title_prefix_cosine_similarity',\n",
    "    'title_query_cosine_similarity_max', 'title_query_cosine_similarity_min',\n",
    " 'title_query_cosine_similarity_mean', 'title_query_cosine_similarity_std',\n",
    "    'title_prefix_leven', 'title_prefix_leven_rate',\n",
    " 'title_query_leven_sum', 'title_query_leven_max', 'title_query_leven_min',\n",
    " 'title_query_leven_mean', 'title_query_leven_std',\n",
    "    'prefix', 'query_prediction', 'title', 'tag', 'label',\n",
    "      ]\n",
    "\n",
    "train_fea = fea + ['index']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导出特征工程文件\n",
    "def exportDf(df, fileName):\n",
    "    df.to_csv('../temp/%s.csv' % fileName, header=True, index=True)\n",
    "\n",
    "exportDf(train_df[train_fea], 'train_offline_alldata_df')\n",
    "exportDf(valid_df[fea], 'valid_offline_alldata_df')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
